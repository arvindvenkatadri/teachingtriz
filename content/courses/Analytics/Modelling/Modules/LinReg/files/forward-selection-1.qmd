---
title: "Tutorial: Multiple Linear Regression with Forward Selection"
author: "Arvind V."
date: 13/May/2023
date-modified: "`r Sys.Date()`"
categories: 
  - Linear Regression
  - Quantitative Predictor
  - Quantitative Response
  - Sum of Squares
  - Residuals
abstract: "Using Multiple Regression to predict Quantitative Target Variables"
bibliography: 
  - grateful-refs.bib
citation: true
#suppress-bibliography: true
---

## {{< iconify noto-v1 package >}} Setting up R Packages

```{r}
#| label: setup
#| message: true
#| warning: false
options(scipen = 1, digits = 3) #set to three decimal 
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE) 
library(tidyverse)
library(ggformula)
library(mosaic)
library(GGally)
library(corrgram)
library(corrplot)
library(broom)

# datasets
library(ISLR)

```


```{r}
#| label: Extra Pedagogical Packages
#| echo: false
#| message: false

library(checkdown)
library(epoxy)
library(TeachHist)
library(TeachingDemos)
library(grateful)

```

```{r}
#| label: plot theme
# Let us set a plot theme for Data visualization

theme_set(theme_light(base_size = 11, base_family = "Roboto Condensed"))

theme_update(
  panel.grid.minor = element_blank(),
  plot.title = element_text(face = "bold"),
  plot.title.position = "plot"
)


```

In this tutorial, we will use the ~~Boston housing~~ `Hitters`
dataset**(s)** from the `ISLR` package. Our research question is:

::: callout-note
## Research Question

How do we predict the `Salary` of baseball players based on other
**Quantitative** parameters such as `Hits`, `HmRun` `AtBat`?

And how do we choose the "best" model, based on a trade-off between
Model Complexity and Model Accuracy?
:::




## {{< iconify flat-color-icons workflow >}} Workflow Plan

Our target variable is `Salary`.

We will start with an examination of correlations between `Salary` and
other Quant predictors.

We will use a null model for our Linear Regression at first, keeping
just an `intercept` term. Based on the examination of the *r-square*
improvement offered by each predictor *individually*, we will add
another quantitative predictor. We will follow this process through up
to a point where the gains in model accuracy are good enough to justify
the additional model complexity.

::: callout-note
This approach is the exact opposite of the earlier tutorial on multiple
linear regression, where we started with a **maximal model** and trimmed
it down based on an assessment of `r.squared`.
:::



## {{< iconify flat-color-icons workflow >}} Workflow: EDA

The `Hitters` dataset has the following variables:

```{r}

data("Hitters")
inspect(Hitters)

```



### {{< iconify flat-color-icons scatter-plot >}} Scatter Plots and Correlations

We should examine scatter plots and Correlations of `Salary` against these variables. Let us select a few sets of Quantitative and Qualitative features, along with the target variable `Salary` and do a pairs-plots with them:

```{r}
#| label: pairs plots 1
#| message: false
#| warning: false
#| column: screen-inset-shaded
#| layout-nrow: 2

Hitters %>% 
  select(Salary, AtBat, Hits, HmRun) %>% 
  GGally::ggpairs(title = "Plot 1", lower = list(continuous = wrap("smooth", alpha = 0.2)))

Hitters %>% 
  select(Salary, Runs, RBI, Walks,Years) %>% 
  GGally::ggpairs(title = "Plot 2", lower = list(continuous = wrap("smooth", alpha = 0.2)))

Hitters %>% 
  select(Salary, CRBI, CAtBat, CHits, CHmRun, CRuns, CWalks) %>% 
  GGally::ggpairs(title = "Plot 3", lower = list(continuous = wrap("smooth", alpha = 0.2)))


Hitters %>% 
  select(Salary, PutOuts,Assists,Errors) %>% 
  GGally::ggpairs(title = "Plot 4", lower = list(continuous = wrap("smooth", alpha = 0.2)))

Hitters %>% 
  select(Salary, League,Division,NewLeague) %>% 
  GGally::ggpairs(title = "Plot 5", lower = list(continuous = wrap("smooth", alpha = 0.2)))

```

`AtBat` and `Hits` seem relevant predictors for `Salary`. So are `Runs`,
`RBI`,`Walks`, and `Years`. From Plot 2, both `RBI` and `Walks` are also
inter-correlated with `Runs`. All the `C*` variables are well correlated
with `Salary` and also among one another. (Plot3). Plot 4 has no
significant correlations at all. Plot 5 shows `Salary` nearly equally
distributed across `League`, `Division`, and `NewLeague`.




### {{< iconify carbonchart-error-bar-alt >}} Correlation Error-Bars

We can also plot all correlations in one graph using `cor.test` and
`purrr`:

```{r}
#| label: corr-test plots
#| layout-nrow: 1

all_corrs <- 
  Hitters %>% 
  select(where(is.numeric)) %>% 
  
  # leave off Salary and year to get all the remaining ones
  select(- Salary) %>% 
  
  
  # perform a cor.test for all variables against Salary
  purrr::map(.x = .,
             .f = \(x) cor.test(x, Hitters$Salary)) %>%
  
  # tidy up the cor.test outputs into a tidy data frame
  map_dfr(broom::tidy, .id = "predictor") %>% 
  arrange(desc(estimate))

all_corrs

all_corrs %>%
  gf_hline(yintercept = 0,
           linewidth = 2,
           color = "grey") %>%
  gf_errorbar(
    conf.high + conf.low ~ reorder(predictor, estimate),
    color = ~ estimate,
    linewidth =  ~ -log10(p.value),
    width = 0.5,
    caption = "Significance = -log10(p.value)"
  ) %>%
  gf_point(estimate ~ reorder(predictor, estimate)) %>%
  gf_labs(x = NULL, y = "Correlation with Salary") %>%
  #gf_theme(theme = my_theme()) %>%
  gf_refine(
    scale_colour_distiller("Correlation", type = "div",
                           palette = "RdBu"),
    scale_linewidth_continuous("Significance", range = c(0.25, 3))
  ) %>%
  gf_refine(guides(linewidth = guide_legend(reverse = TRUE)),
            theme(axis.text.x = element_text(hjust = 1))) %>%
  gf_refine(guides(linewidth = guide_legend(reverse = TRUE)),
            coord_flip())

```

There are a good many predictors which have statistically significant
correlations with `Salary`, such as `CRuns` , `CHmRun`. The darker the colour, the higher is the correlation score; the fatter the bar, the higher is the significance of the correlation.

We now start with setting up simple Linear Regressions with **no**
predictors, only an intercept. We then fit separate Linear Models using
each predictor **individually**. Then based on the the improvement in
`r.squared` offered by each predictor, we progressively add it to the
model, until we are "satisfied" with the quality of the model ( using
`rsquared` and other means).

Let us now do this.



## {{< iconify flat-color-icons workflow >}} Workflow: Minimal Multiple Regression Model

Note the formula structure here: we want just and `intercept`.


```{r}
lm_min <- lm(data = Hitters, Salary ~ 1)
summary(lm_min)

```

```{r}
#| layout-ncol: 2
lm_min %>% broom::tidy()
lm_min %>% broom::glance()

```




OK, so the intercept is highly significant, the `t-statistic` is also
high, but the intercept contributes *nothing* to the `r.squared`!! It is of no use at all!





## {{< iconify flat-color-icons workflow >}} Workflow: Predictor Addition (Round#1)

We will now set up individual models for each predictor and look at the
`p.value` and `r.squared` offered by each separate model:


```{r}
#| label: Round1-All individual models at once
#| layout-nrow: 1

names <- names(Hitters %>%
  select(where(is.numeric), 
         -c(Salary)))

n_vars <- length(names)

Hitters_model_set <- tibble(all_vars = list(names),
                            keep_vars = seq(1, n_vars),
                            data = list(Hitters))

# Unleash purrr in a series of mutates
Hitters_model_set <- Hitters_model_set %>%
  
# Select Single Predictor for each Simple Model
  mutate(mod_vars =
           pmap(
             .l = list(all_vars, keep_vars, data),
             .f = \(all_vars, keep_vars, data) all_vars[keep_vars]
           )) %>%
  
# build formulae with these for linear regression
  mutate(formula = map(.x = mod_vars,
                       .f = \(mod_vars) as.formula(paste(
                         "Salary ~", paste(mod_vars, collapse = "+")
                       )))) %>%
  
# use the formulae to build multiple linear models
  mutate(models =
           pmap(
             .l = list(data, formula),
             .f = \(data, formula) lm(formula, data = data)
           ))


# Tidy up the models using broom to expose their metrics
Hitters_model_set <- 
  Hitters_model_set %>% 
  mutate(tidy_models =
           map(
             .x = models,
             .f = \(x) broom::glance(x,
                                     conf.int = TRUE,
                                     conf.lvel = 0.95)
           ),
         predictor_name = names[keep_vars]) %>% 

  # Remove unwanted columns, keep model and predictor count
  select(keep_vars,predictor_name, tidy_models) %>%
  unnest(tidy_models) %>% 
  arrange(desc(r.squared))

# Check everything after the operation
Hitters_model_set

# Plot r.squared vs predictor count
Hitters_model_set %>% 
  gf_point(r.squared ~ reorder(predictor_name, r.squared), 
           size = 3.5, 
           color = "black",
           ylab = "R.Squared",
           xlab = "Params in the Linear Model", data = .) %>%
  #gf_theme(my_theme()) %>% 
  gf_refine(theme(axis.text.x = element_text(angle = 30,
                                             hjust = 1)))

```



```{r}
# Which is the winning Predictor?
winner <- Hitters_model_set %>% 
  arrange(desc(r.squared)) %>% 
  select(predictor_name) %>% 
  head(1) %>% as.character()
winner

```


```{r}
#| layout-nrow: 1
# Here is the Round 1 Model
# Minimal model updated to included winning predictor
lm_round1 <- update(lm_min, ~. + CRBI)
lm_round1 %>% broom::tidy()
lm_round1 %>% broom::glance()

```




So we can add `r winner` as a predictor to our model as a predictor gives us an improved `r.squared` of $0.321$, which is the square of the correlation between `Salary` and `CRBI`, $.567$.

And the model itself is: 
$$
Salary \sim 274.580 + 0.791 \times CRBI
$$ {#eq-round1}

Let's press on to Round 2.



## {{< iconify flat-color-icons workflow >}} Workflow: Predictor Addition (Round #2)

We will set up a **round-2** model using `CRBI` as the predictor, and
then proceed to add each of the other predictors as an `update` to the
model.


```{r}
#| label: Round 2
#| warning: false
#| layout-nrow: 1

# Preliminaries
names <- names(Hitters %>%
  select(where(is.numeric), -c(Salary, winner)))
# names

n_vars <- length(names)
# n_vars
# names <- names %>% str_remove(winner)
# names
# n_vars <- n_vars-1


# Round 2 Iteration
Hitters_model_set <- tibble(all_vars = list(names),
                            keep_vars = seq(1, n_vars),
                            data = list(Hitters))
# Hitters_model_set 

# Unleash purrr in a series of mutates
Hitters_model_set <- Hitters_model_set %>%
  
# list of predictor variables for each model
  mutate(mod_vars =
           pmap(
             .l = list(all_vars, keep_vars, data),
             .f = \(all_vars, keep_vars, data) all_vars[keep_vars]
           )) %>%
  
# build formulae with these for linear regression
  mutate(formula = map(.x = mod_vars,
                       .f = \(mod_vars) as.formula(paste(
                         "Salary ~ CRBI +", paste(mod_vars, collapse = "+")
                       )))) %>%
  
# use the formulae to build multiple linear models
  mutate(models =
           pmap(
             .l = list(data, formula),
             .f = \(data, formula) lm(formula, data = data)
           ))
# Check everything after the operation
# Hitters_model_set

# Tidy up the models using broom to expose their metrics
Hitters_model_set <- 
  Hitters_model_set %>% 
  mutate(tidy_models =
           map(
             .x = models,
             .f = \(x) broom::glance(x,
                                     conf.int = TRUE,
                                     conf.lvel = 0.95)
           ),
         predictor_name = names[keep_vars]) %>% 

  # Remove unwanted columns, keep model and predictor count
  select(keep_vars,predictor_name, tidy_models) %>%
  unnest(tidy_models) %>% 
  arrange(desc(r.squared))

Hitters_model_set

# Plot r.squared vs predictor count
Hitters_model_set %>% 
  gf_point(r.squared ~ reorder(predictor_name, r.squared), 
                               size = 3.5,
                               ylab = "R.Squared",
                               xlab = "Param in the Linear Model") %>%
  #gf_theme(my_theme()) %>% 
  gf_refine(theme(axis.text.x = element_text(angle = 30, 
                                             hjust = 1)))

```





```{r}
#| layout-nrow: 1
# Which is the winning Predictor?
# 
winner <- Hitters_model_set %>% 
  arrange(desc(r.squared)) %>% 
  select(predictor_name) %>% 
  head(1) %>% as.character()
winner

# Here is the Round 1 Model
lm_round2 <- update(lm_round1, ~. + Hits)
lm_round2 %>% broom::tidy()
lm_round2 %>% broom::glance()

```

And now the model itself is: 
$$
Salary \sim -47.96 + 0.691 \times CRBI + 3.30 \times Hits
$$ {#eq-round2}

Note the change in both `intercept` and the `slope` for `CRBI` when the
new predictor `Hits` is added!!




## {{< iconify openmoji chart-increasing >}} Workflow: Visualization

Let us quickly see how this model might look. We know that with simple
regression, we obtain a straight line as our model. Here, with two (or
more) predictors, we should obtain a ....(hyper)plane! Play with the interactive plot below!

```{r,}
#| echo: false
#| message: false
#| warning: false
library(plotly)
library(modelr)

lm_round2_aug <- lm_round2 %>% broom::augment()
lm_round2_aug

# Prediction Matrix

CRBI_axis <- seq(min(Hitters$CRBI), max(Hitters$CRBI), length.out = 25)
Hits_axis <- seq(min(Hitters$Hits), max(Hitters$Hits), length.out = 25)

# Create Prediction Grid for Regression Plan
pred_grid <- expand.grid(CRBI = CRBI_axis,
                         Hits = Hits_axis) %>%
  modelr::add_predictions(lm_round2)

# Convert to matrix for plotly
pred_mx <- matrix(pred_grid$pred,
                  ncol = 25,
                  nrow = 25)

lm_round2_aug %>% 
  plot_ly(x = ~ CRBI, 
        y = ~ Hits, 
        z = ~ Salary) %>% 
  add_markers() %>%
  add_surface(x = ~ CRBI_axis, 
              y = ~ Hits_axis, 
              z = ~ pred_mx) %>% 
  
  layout(title = "Salaries of Baseball Players")

```

## {{< iconify octicon feed-discussion-16 >}} Discussion

It is interesting that the second variable to be added was `Hits` which
has a lower correlation of $r = 0.439$ with `Salary` compared to some other
Quant predictors such as `Chits`( $r = 0.525$ ). This is because `CRBI` is
hugely correlated with all of these predictors, so `CRBI` effectively
acts as a proxy for all of these. See Plot 3.

We see that adding `Hits` to the model gives us an improved `r.squared`
of $0.425$.

## {{< iconify fluent-mdl2 decision-solid >}} Conclusion

We can proceed in this way to subsequent rounds and decide to stop when
the model complexity (no. of predictors ) and the resulting gain in
`r.squared` does not seem worth it.

::: callout-note
### Automatic Iteration Method

We ought to convert the above code into an R `function` and run it that
way for a specific number of rounds to see how things pan out. ~~That is
in the next version of this Tutorial!~~ It appears that there is, what else, an R Package, called `reghelper` that allows us to do this! ðŸ˜‡
The `reghelper::build_model()` function can be used to:\

- Start with only an intercept\
- Sequentially add each of the other predictor variables into the model "blocks"\
- Blocks will be added in the order they are passed to the function, and variables from previous blocks will be included with each subsequent block, so they do not need to be repeated.\

Type `help(rehelper)` in your Console.


```{r}
#| layout-ncol: 2
#| column: page-inset-right
library(reghelper)

big_model <- build_model(
  dv = Salary, 
  # Start with only an intercept lm(Salary ~ 1, data = .)
  
  # Sequentially add each of the other predictor variables
  # Pass through variable names (or interaction terms) to add for each block. 
  # To add one term to a block, just pass it through directly; 
  # to add multiple terms at a time to a block, pass it through in a vector or list. 
  # Interaction Terms can be specified using the vector/list
  # Blocks will be added in the order they are passed to the function
  # Variables from previous blocks will be included with each subsequent block,  so they do not need to be repeated.
  
  1, AtBat, Hits, HmRun, Runs, RBI, Walks, Years, CAtBat, CHits, 
  CHmRun, CRuns, CRBI, CWalks, PutOuts, Assists, Errors,
  
  data = Hitters, 
  model = 'lm')

```

This multiple model is a `list` object with 4 items. Type `summary(big_model)` in your Console.

We can clean it up a wee bit:

```{r}
#| label: clean-helper-summary
#| column: page-inset-right
library(gt)
# big_model has 4 parts: formulas, residuals, coefficients, overall

overall_clean <- summary(big_model)$overall %>% as_tibble() %>% janitor::clean_names()

formulas_clean <- summary(big_model)$formulas %>% 
  as.character() %>% as_tibble() %>% 
  rename("model_formula" = value)

all_models <- cbind(formulas_clean, overall_clean) %>% 
  dplyr::select(1,2,8)
all_models %>% 
  gt::gt() %>% 
    tab_style(style = cell_fill(color = "grey"),
            locations = cells_body(rows = seq(1, 18, 2)))

```


So we have a list of all models with **main effects** only. We could play with the `build_model` function to develop interaction models too!
Slightly weird that the NULL model of `Salary~1` does not show an `r.squared` value with `build_model`...??
:::

## {{< iconify ooui references-rtl >}} References
::: {#refs style="font-size: 60%;"}
\
<https://ethanwicker.com/2021-01-11-multiple-linear-regression-002/>


###### {{< iconify lucide package-check >}} R Package Citations

```{r}
#| echo: false
#scan_packages()
cite_packages(
  output = "table",
  out.dir = ".",
  out.format = "html",
  pkgs = c("corrgram", "corrplot", "GGally","gt",
           "infer", "ISLR", "janitor", "reghelper")
) %>%
  knitr::kable(format = "simple")

```

:::

