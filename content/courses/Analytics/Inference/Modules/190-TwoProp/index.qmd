---
title: "\U0001F0CF Inference Test for Two Proportions"
author: "Arvind V."
date: 10/Nov/2022
abstract: "Inference Test for Two Proportions"
lastmod: "`r Sys.Date()`"
order: 190
image: preview.jpg
image-alt: From The Internet Archive
categories:
- Permutation
- Monte Carlo Simulation
- Random Number Generation
- Distributions
- Generating Parallel Worlds
bibliography: 
  - grateful-refs.bib
citation: true
#suppress-bibliography: true
editor: 
  markdown: 
    wrap: 72
---

## {{< iconify noto-v1 package >}} Setting up R packages

```{r}
#| label: setup
#| include: true
library(tidyverse)
library(mosaic)
library(ggmosaic) # plotting mosaic plots for Categorical Data

### Dataset from Chihara and Hesterberg's book (Second Edition)
library(resampledata)
library(vcd)

```

```{r}
#| label: Extra Pedagogical Packages
#| echo: false
#| message: false
library(tinytable)
library(checkdown)
library(epoxy)
library(TeachHist)
library(TeachingDemos)
library(grateful)

```

#### Plot Theme

```{r}
#| label: Plot Sizing and theming
#| code-fold: true
#| message: false
#| results: hide

# https://stackoverflow.com/questions/74491138/ggplot-custom-fonts-not-working-in-quarto

# Chunk options
knitr::opts_chunk$set(
 fig.width = 7,
 fig.asp = 0.618, # Golden Ratio
 #out.width = "80%",
 fig.align = "center"
)
### Ggplot Theme
### https://rpubs.com/mclaire19/ggplot2-custom-themes

theme_custom <- function(){ 
    font <- "Roboto Condensed"   #assign font family up front
   
    theme_classic(base_size = 14) %+replace%    #replace elements we want to change
    
    theme(
      panel.grid.minor = element_blank(),    #strip minor gridlines
      text = element_text(family = font),
      #text elements
      plot.title = element_text(             #title
                   family = font,            #set font family
                   #size = 20,               #set font size
                   face = 'bold',            #bold typeface
                   hjust = 0,                #left align
                   #vjust = 2                #raise slightly
                   margin=margin(0,0,10,0)
),               
      
      plot.subtitle = element_text(          #subtitle
                   family = font,            #font family
                   #size = 14,                #font size
                   hjust = 0,
                   margin=margin(2,0,5,0)
),               
      
      plot.caption = element_text(           #caption
                   family = font,            #font family
                   size = 8,                 #font size
                   hjust = 1),               #right align
      
      axis.title = element_text(             #axis titles
                   family = font,            #font family
                   size = 10                 #font size
),
      
      axis.text = element_text(              #axis text
                   family = font,            #axis family
                   size = 8)               #font size
    )
}

# Set graph theme
theme_set(new = theme_custom())
#
```

:::: {.pa4}
::: {.athelas .ml0 .mt0 .pl4 .black-90 .bl .bw2 .b--blue}
[Early in life I had to choose between honest arrogance and hypocritical humility. I chose the former and have seen no reason to change.]{.f5 .f4-m .f3-l .lh-copy .measure .mt0}

[ --- Frank Lloyd Wright]{.f6 .ttu .tracked .fs-normal}
:::
::::


## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction

Many experiments gather qualitative data across different segments of a
population, for example, opinion about a topic among people who belong to
different income groups, or who live in different parts of a city. This
should remind us of the [Likert
Plots](../../../Descriptive/Modules/45-SurveyData/index.qmd) that we
plotted earlier. In this case the two variables, dependent and
independent, are both Qualitative, and we can calculate [counts and
proportions](../../../Descriptive/Modules/40-CatData/index.qmd).

How does one Qual variable affect the other? How do counts/proportions
of the `dependent variable` vary with the `levels` of the `independent`
variable? This is our task for this module.

Here is a quick example of the kind of data we might look at here, taken
from the [British Medical
Journal](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests):

![Breast
Feeding](../../../../../materials/images/table-83.webp){#fig-breast-feeding}

Clearly, we can see differences in [counts/proportions of women who
breast-fed their babies for three months or more]{.black .bg-pink}, ***based on*** whether
they were ["printers wives" or "farmers' wives"]{.black .bg-green}! 

Is there a doctor in the
[House](https://www.imdb.com/title/tt0412142/)?

### {{< iconify flat-color-icons workflow >}} The CLT for Two Proportions

We first need to establish some model assumptions prior to making our
analysis. As before, we wish to see if the CLT applies here, and if so,
in what form. The difference between two proportions $\hat{p_1}-\hat{p_2}$ can be modeled using a normal distribution when:

-   **Independence (extended)**: The data are independent within and between
    the two groups. Generally this is satisfied if the data come from
    two independent random samples or if the data come from a randomized
    experiment.
-   **Success-failure condition**: The success-failure condition holds
    for both groups, where we check successes and failures in each group
    separately. That is, we should have at least 10 successes and 10
    failures in each of the two groups.

When these conditions are satisfied, the standard error of
$\hat{p_1}-\hat{p_2}$ is well-approximated by:

$$
SE(\hat{p_1}-\hat{p_2}) = \sqrt{\frac{\hat{p_1}*(1-\hat{p_1})}{n_1}} + \sqrt{\frac{\hat{p_2}*(1-\hat{p_2})}{n_2}}
$$

where $\hat{p_1}$ and $\hat{p_2}$ represent the sample proportions, and
$n_1$ and $n_2$ represent the sample sizes.

We can represent the Confidence Intervals as:

$$
\begin{eqnarray}
CI(p_1 - p_2) &=& (\hat{p_1} - \hat{p_2}) \pm 1.96 * SE(\hat{p_1}-\hat{p_2})\\
&=& (\hat{p_1} - \hat{p_2}) \pm 1.96 * \left(\sqrt{\frac{\hat{p_1}*(1-\hat{p_1})}{n_1}} + \sqrt{\frac{\hat{p_2}*(1-\hat{p_2})}{n_2}}\right)
\end{eqnarray}
$$

## {{< iconify grommet-icons test >}} {{< iconify lucide ratio >}} Case Study-1: `GSS2002` dataset

We saw how we could perform inference for a single proportion. We can
extend this idea to *multiple proportions* too.

Let us try a dataset with Qualitative / Categorical data. This is the
`General Social Survey GSS dataset` from the [`resampledata`
package](https://github.com/rudeboybert/resampledata), and we have
people with different levels of `Education` stating their opinion on the
`Death Penalty`. We want to know if these two Categorical variables have
a correlation, i.e. can the opinions in favour of the `Death Penalty` be
explained by the `Education` level?

Since data is Categorical ( both variables ), we need to take `counts`
in a table, and then implement a `chi-square test`. In the test, we will
permute the `Education` variable to see if we can see how significant
its *effect size* is.

```{r}

data(GSS2002, package = "resampledata")
glimpse(GSS2002)
inspect(GSS2002)
skimr::skim(GSS2002)

```

<br>

Note how *all* variables are Categorical !! `Education` has five
`levels`, and of course `DeathPenalty` has three:

```{r}

GSS2002 %>% count(Education)
GSS2002 %>% count(DeathPenalty)

```

Let us drop NA entries in `Education` and `Death Penalty` and set up a
[**Contingency
Table**](../../../Descriptive/Modules/40-CatData/index.qmd#what-is-a-contingency-table).

```{r,warning=FALSE,message=FALSE}

gss2002 <- GSS2002 %>% 
  dplyr::select(Education, DeathPenalty) %>% 
  tidyr::drop_na(., c(Education, DeathPenalty))
##
gss_table <- mosaic::tally(DeathPenalty ~ Education, data = gss2002) %>% 
  addmargins()
gss_table 

```

### Contingency Table Plots

The Contingency Table can be plotted, as we have seen, using a
`mosaic`plot using several packages. Let us do a quick recap:

::: {.panel-tabset .nav-pills style="background: whitesmoke;"}

#### Using vcd

```{r}
mosaic::tally(DeathPenalty ~ Education, data = gss2002) %>% 
  vcd::mosaic(gp = shading_hsv)

```

#### Using ggmosaic

```{r mosaic-plot,warning=FALSE}
#library(ggmosaic)

# Set graph theme
theme_set(new = theme_custom())
#
ggplot(data = gss2002) +
  geom_mosaic(aes(x = product(DeathPenalty, Education), 
                  fill = DeathPenalty))

```

#### Using ggformula

As seen before, it needs a little more work, to convert the Contingency
Table into a tibble:

```{r warning=FALSE,message=FALSE}
# https://stackoverflow.com/questions/19233365/how-to-create-a-marimekko-mosaic-plot-in-ggplot2

# Set graph theme
theme_set(new = theme_custom())
#

gss_summary <- gss2002 %>%
  mutate(
    Education = factor(
      Education,
      levels = c("Bachelors", "Graduate", "Jr Col", "HS", "Left HS"),
      labels = c("Bachelors", "Graduate", "Jr Col", "HS", "Left HS")
    ),
    DeathPenalty = as.factor(DeathPenalty)
  ) %>%
  group_by(Education, DeathPenalty) %>%
  summarise(count = n()) %>% # This is good for a chisq test
  
  # Add two more columns to facilitate mosaic/Marrimekko Plot
  mutate(edu_count = sum(count), 
         edu_prop = count / sum(count)) %>%
  ungroup() 
###
gf_col(edu_prop ~ Education, data = gss_summary,
       width = ~ edu_count, 
       fill = ~ DeathPenalty,
       stat = "identity", 
       position = "fill", 
       color = "black") %>% 
  
  gf_text(edu_prop ~ Education, 
          label = ~ scales::percent(edu_prop),
          position = position_stack(vjust = 0.5)) %>% 
  
  gf_facet_grid(~ Education, 
                scales = "free_x", 
                space = "free_x") %>% 
  
  gf_theme(scale_fill_manual(values = c("orangered", "palegreen3"))) 

```
:::

## Hypotheses Definition

What would our Hypotheses be relating to the *proportions* of votes for or against the Death Penalty?

$H_0: \text{Education does not affect votes for Death Penalty}\\$

$H_a: \text{Education affects votes for Death Penalty}\\$

## Inference for Two Proportions

We are now ready to perform our statistical inference. We will use the
standard `Pearson chi-square test`, and develop and intuition for it. We
will then do a permutation test to have an alternative method to
complete the same task.

::: {.panel-tabset .nav-pills style="background: whitesmoke;"}
### Code

Let us now perform the base `chisq test`: We need a `contingency table` and then the `chisq` test: We will calculate the `observed-chi-squared` value, and compare it with the `critical value`.

```{r}

# Chi-square test
mosaic::xchisq.test(mosaic::tally(DeathPenalty ~ Education, data = gss2002))


# Get the observed chi-square statistic
observedChi2 <- mosaic::chisq(mosaic::tally(DeathPenalty ~ Education, data = gss2002))
observedChi2

# Determine the Chi-Square critical value
X_squared_critical <- qchisq(p = .05, 
       df = (5-1)*(2-1), # (nrows-1) * (ncols-1)
       lower.tail = FALSE)
X_squared_critical

```

We see that our observed $X^2 = 23.45$; the critical value
`X_squared_critical` is $9.48$, which is much smaller! The `p-value` is
$0.0001029$, very low as we would expect, indicating that the NULL
Hypothesis should be rejected in favour of the alternate hypothesis,
that opinions about the `DeathPenalty` are related to `Education`.

```{r}
#| echo: false
mosaic::xqchisq(p = c(0.025, 0.975), 2, 2,
               return = c("plot"), verbose = T,
        system = "gg") %>%  
   gf_labs(title = "Critical Chi-Square Value", 
 x = "") %>% 
  gf_vline(xintercept = observedChi2, color = "red", linewidth = 1) %>%
  gf_refine(annotate(x = 21, y = 0.15, geom = "text", label = "Observed\n Chi-Square")) %>% 
   gf_theme(theme_classic())
 
```

Let us now dig into that cryptic-looking table above!

### Intuitive Explanation

Let us look at the Contingency Table that we have:

```{r}
#| label: fig-sample-contingency-table-picture
#| fig-cap: "Contingency Table"
#| echo: false

data("GSS2002", package = "resampledata")
gss2002 <- GSS2002 %>% 
  dplyr::select(Education, DeathPenalty) %>% 
  tidyr::drop_na(., c(Education, DeathPenalty))

mosaic::tally(DeathPenalty ~ Education, data = gss2002) %>% 
  addmargins() %>% 
  as_tibble() %>% 
  pivot_wider(id_cols = DeathPenalty, names_from = Education, values_from = n) %>% 
  tt() %>% 
  style_tt(color = "grey") %>% 
  style_tt(i = 1, j = 2, color = "black", bold = TRUE, background = "yellow") %>% 
  style_tt(i = 2, j = 5, color = "black", bold = TRUE, background = "yellow") %>% 
   style_tt(i = 3, color = "black", bold = TRUE, background = "palegreen") 

```


```{r echo=FALSE}
#| eval: false
mosaic::tally(DeathPenalty ~ Education, data = gss2002) %>% 
  addmargins() %>% 
  kableExtra::kbl(caption = "Contingency Table") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Cambria")

```

<br> In the chi-square test, we check whether the two (or more)
categorical variables are independent. To do this we perform a simple
check on the Contingency Table. We first *re-compute* the totals in each
row and column, based on what we could **expect** ***if there was
independence (NULL Hypothesis)***. If the two variables were independent,
then there should be **no difference** between real and expected scores.

How do we know [what scores to expect]{.black .bg-light-red} if there was
no relationship between the variables?

Consider the entry in location (1,1): 117. The number of **expected**
entries there is the *probability of an entry landing in that square*
times *the total number of entries*:

$$
\begin{align}
\text{Expected Value[1,1]}
&= p_{row_1} * p_{col_1} * Total~Scores\\\
&= \Large{\frac{\sum_{r_{1}}}{\sum_{r_{all}c_{all}}} * \frac{\sum_{c_{1}}}{\sum_{r_{all}c_{all}}} * \sum_{r_{all}c_{all}}} \\
&= \frac{898}{1307} * \frac{189}{1307} * 1307\\\
&= 130
\end{align}
$$

Proceeding in this way for all the 15 entries in the Contingency Table,
we get the "Expected" Contingency Table. Here are both tables for
comparison:

```{r}
#| echo: false
# using prop.table with appropriate margin argument gives us a slick matrix of probabilities
mosaic::tally(DeathPenalty ~ Education, 
              data = gss2002) %>% 
  addmargins() -> gss_sub_table
##
gss_exp <- gss_sub_table * gss_sub_table / ((
  prop.table(gss_sub_table, margin = 1) * prop.table(gss_sub_table, margin = 2)) * 1307 * 4)
gss_exp %>% 
   kableExtra::kbl(caption = "Expected Contingency Table", 
                   digits = 0) %>%
  kableExtra::kable_classic(full_width = F, 
                            html_font = "Cambria")
```

```{r}
#| eval: false
#| echo: false
gss_exp %>% 
   kableExtra::kbl(caption = "Expected Contingency Table", 
                   digits = 0) %>%
  kableExtra::kable_classic(full_width = F, 
                            html_font = "Cambria")
```

```{r}
#| echo: false
gss_table %>%  
   kableExtra::kbl(caption = "Actual Contingency Table") %>%
  kableExtra::kable_classic(full_width = F, html_font = "Cambria")

```

And here are the mosaic plots for the *actual* and *expected* Contingency Tables, along with the *association* plot showing the differences, as we did when plotting [Proportions](../../../Descriptive/Modules/40-CatData/index.qmd#coloured-tiles-actual-and-expected-contingency-tables):


```{r}
#| echo: false
#| layout-ncol: 3
#| fig-subcap: 
#|  - "Actual"
#|  - "Expected"
#|  - "Tile-Wise Differences"
counts_table <- mosaic::tally(DeathPenalty ~ Education, data = gss2002) # No margins added
vcd::mosaic(counts_table)
vcd::mosaic(counts_table, type = "expected")
vcd::assoc(counts_table)

```

<br> 

Now, the **Pearson Residual** in each cell is equivalent to the
`z-score` of that cell. Recall the [z-score](../22-Histograms/index.qmd#z-scores) idea: we subtract the mean and divide by the std. deviation to get the `z-score`.

In the Contingency Table, we have **counts** which are usually modeled
as an (integer) *Poisson distribution*, for which **mean (i.e Expected
value) and variance are identical**. Thus we get the Pearson Residual
as:

$$
r_{i,j} = \frac{(Actual - Expected)}{\sqrt{\displaystyle Expected}}
$$ 

and therefore:


$$
r_{i,j} = \frac{(o_{i,j}- e_{i,j})}{\sqrt{\displaystyle e_{i,j}}}
$$


The sum of all the squared Pearson residuals is the chi-square
statistic, χ2, upon which the inferential analysis follows. 

$$
χ2 = \sum_{i=1}^R\sum_{j=1}^C{r_{i,j}^2} 
$$ 


where R and C are number of rows and columns in the Contingency
Table, the levels in the two Qual variables.

For location \[1,1\], its contribution to χ2 would be: $(117-130)^2/130 = 1.3$. 
Do try to compute all of these and the $X^2$ statistic by hand !!

All right, what of all this? How did this $X^2$ distribution come from?
Here is a lovely, brief explanation from this [StackOverflow
Post](https://stats.stackexchange.com/a/303548):

> -   In a Contingency Table the Null Hypothesis states that the
>     variables in the rows and the variable in the columns are
>     independent.\
> -   The cell counts $E_{ij}$ are assumed to be [Poisson distributed]{.bg-light-red .black} with mean = $E_{ij}$ and as they are Poisson, their variance is
>     also $E_{ij}$.\
> -   Asymptotically the Poisson distribution approaches the [normal
>     distribution]{.bg-light-red .black}, with mean = $E_{ij}$ and *standard deviation* with
>     $\sqrt{E_{ij}}$ so, asymptotically
>     $\large{\frac{(X_{ij} - E_{ij})}{\sqrt{E_{ij}}}}$ is approximately
>     standard normal $N(0,1)$.\
> -   If you square standard normal variables and sum these squares then
>     the result is a chi-square random variable so
>     $\sum_{i,j}\left(\frac{(X_{ij}-E_{ij})}{\sqrt{E_{ij}}}\right)^2$
>     has a (asymptotically) a [chi-square
>     distribution]{.bg-light-red .black}.\
> -   Asymptotics must hold and that is why most textbooks state that
>     the result of the test is valid when all expected cell counts
>     $E_{ij}$ are larger than 5, but that is just a rule of thumb that
>     makes the approximation ''good enough''.


```{r}
#| echo: false
#| warning: false
#| layout-ncol: 2

# Set graph theme
theme_set(new = theme_custom())
#
df <- tibble(x = rnorm(500, mean = 0, sd = 2), 
             y = x^2)
df %>% gf_density(~x) %>% 
  gf_fitdistr(dist = "dnorm", title = "Normal Density")
##
df %>% gf_density(~y) %>% 
  gf_fitdistr(dist = "dchisq",start = list(df = 4),
              title = "Chi-Square Density = Squared Normal Density")

```
:::


## Permutation Test for `Education`

We will now perform the permutation test for the difference between
proportions. We will first get an intuitive idea of the permutation, and
then perform it using both `mosaic` and `infer`.

::: {.panel-tabset .nav-pills style="background: whitesmoke;"}
### {{< iconify svg-spinners blocks-shuffle-3 >}} Permutation Visually Demonstrated

We saw from the diagram created by Allen Downey that [there is only one
test](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)!
We will now use this philosophy to develop a technique that allows us to
mechanize several *Statistical Models* in that way, with nearly
identical code. We will first look visually at a permutation exercise.
We will create dummy data that contains the following case study:

> A set of identical resumes was sent to male and female evaluators. The
> candidates in the resumes were of both genders. We wish to see if
> there was difference in the way resumes were evaluated, by male and
> female evaluators. (We use just *one* male and *one* female evaluator
> here, to keep things simple!)

```{r}
#| label: Artificial Data
#| layout-ncol: 2
#| echo: false

set.seed(123456)
data1 <- tibble(evaluator = rep(x = "F", times = 24),
               candidate_selected = sample(c(0,1), 
                               size = 24, 
                               replace = T, 
                                prob = c(0.1, 0.9)))

data2 <- tibble(evaluator = rep(x = "M", times = 24),
               candidate_selected = sample(c(0,1), size = 24, 
                                replace = T, 
                                prob = c(0.6, 0.4)))

#data1
#data2
               
data <-  rbind(data1, data2) %>%
  as_tibble() %>%

  # Create a 4*12 matrix of integer coordinates
  cbind(expand.grid(x = 1:4, y = seq(4, 48,4))) %>%
  mutate(evaluator = as_factor(evaluator))

data %>% 
  select(evaluator, candidate_selected) %>% 
  as_tibble()

summary <- data %>%
  group_by(evaluator) %>%
  summarise(selection_ratio = mean(candidate_selected == "0"),
            count = count(candidate_selected == "0"),
            n = n())
summary

```

```{r}
#| label: Difference in Proportion
#| layout: [[20],[80]]
#| echo: false
#| warning: false
# Set graph theme
theme_set(new = theme_custom())
#
obs_difference <-
  diff(mean(candidate_selected ~ evaluator, data = data))
obs_difference

###
p0 <- data %>%
  
  # knock off the coordinates prior to shuffle
  select(evaluator, candidate_selected) %>%
  #mutate(candidate_selected = shuffle(candidate_selected, replace = FALSE)) %>%
  arrange(evaluator, candidate_selected) %>%
  
  # reassign coordinates
  cbind(., expand.grid(x = 1:4, y = seq(4, 24, 4))) %>% # Not 48!!
  
  ggplot(data = ., aes(
    x = x,
    y = y,
    group = evaluator,
    fill = as_factor(candidate_selected)
  )) +
  geom_point(shape = 21, size = 8) +
  scale_fill_manual(
    name = NULL,
    values = c("red", "blue"),
    labels = c("Rejected", "Selected")
  ) +
  
  # Very important to have scales = "free" !!
  facet_wrap( ~ evaluator, ncol = 1, scales = "free") +
  
  theme_void() +
  theme(
    legend.position = "top",
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    plot.title = element_text(hjust = 0.5)
  ) +
  expand_limits(y = c(0, 28)) +
  
  # Need to give stat_brace two pairs x values and y values
  # as there are two facets
  ggbrace::stat_brace(
    aes(#x = c(4.5, 5.5, 4.5, 5.5),
      # What a hack this is!!
      #y = c(4, 24, 5, 24),
      label = evaluator),
    rotate = 90,
    labelrotate = 0,
    labelsize = 4,
    inherit.aes = TRUE
  )
p0

```

So, we have a solid disparity in percentage of selection between the two
evaluators! Now we pretend that *there is no difference between the
selections made by either set of evaluators*. So we can just:

-   Pool up all the evaluations\
-   Arbitrarily re-assign a given candidate(selected or rejected) to
    either of the two sets of evaluators, by permutation.\

How would that pooled shuffled set of evaluations look like?

```{r}
#| label: Shuffle the data once
#| echo: false

data_shuffled <- data %>%
  mutate(evaluator = shuffle(evaluator))
#data_shuffled %>% select(evaluator, candidate)
data_shuffled %>%
  group_by(evaluator) %>%
  summarise(
    selection_ratio = mean(candidate_selected == "0"),
    count = count(candidate_selected == "0"),
    n = n()
  )
```

```{r}
#| echo: false
#| layout: [[45,-10, 45]]
#| warning: false
data_shuffled %>% 
      group_by(evaluator, candidate_selected) %>% 
      ggplot(aes(x = x, y = y, 
                 group = evaluator, 
                 fill = as_factor(candidate_selected))) + 
      geom_point(shape = 21,size = 8) + 
      scale_fill_manual(name = NULL,
                        values = c("red", "blue"),
                        labels = c("Rejected","Selected")) + 
      theme_void() + theme(legend.position = "top") +
      ggtitle(label = "Pooled Evaluations, Permuted")


data_shuffled %>% 
  
  # knock off the coordinates
  # Do not use "group_by"!! Why not?
  select(evaluator, candidate_selected) %>% 
  arrange(evaluator,candidate_selected) %>% 
  
  # reassign coordinates
  cbind(., expand.grid(x = 1:4, y = seq(4, 24,4))) %>% # Not 48!!
  
  ggplot(data = ., aes(x = x, y = y, 
             group = evaluator, 
             fill = as_factor(candidate_selected))) + 
  geom_point(shape = 21, size = 8) + 
  scale_fill_manual(name = NULL,
                    values = c("red", "blue"),
                    labels = c("Rejected","Selected")) + 
  
  # Very important to have scales = "free" !!
  facet_wrap(~ evaluator, ncol = 1, scales = "free") +
   expand_limits(y = c(0,28)) +

  ggbrace::stat_brace(aes(label = evaluator),
                      rotate = 90,
                      labelrotate = 0,
                      labelsize = 4,
                      inherit.aes = TRUE) +
  theme_void() + 
  theme(legend.position = "top", 
                       strip.background = element_blank(),
                       strip.text.x = element_blank(),
                       plot.title = element_text(hjust = 0.5)) +
  ggtitle(label = "Permuted Evaluations, Grouped")

```

```{r}
#| label: Old code retained
#| echo: false
#| message: false
#| warning: false
#| eval: false

library(patchwork)
p1 + p2 + plot_annotation(tag_levels = "A") + plot_layout(widths = unit(c(7, 10), c('cm', 'cm')))

```

As can be seen, the ratio is different!

We can now check out our Hypothesis that there is *no* bias. We can
shuffle the data many many times, calculating the ratio each time, and
plot the *distribution of the differences in selection ratio* and see
how that artificially created distribution compares with the originally
observed figure from Mother Nature.

```{r}
#| layout: [[60, -10, 30]]
# Set graph theme
theme_set(new = theme_custom())
#
null_dist <- do(4999) * diff(mean(
  candidate_selected ~ shuffle(evaluator), 
  data = data))
# null_dist %>% names()
null_dist %>% gf_histogram( ~ M, 
                  fill = ~ (M <= obs_difference), 
                  bins = 25,show.legend = FALSE,
                  xlab = "Bias Proportion", 
                  ylab = "How Often?",
                  title = "Permutation Test on Difference between Groups",
                  subtitle = "") %>% 
  gf_vline(xintercept = ~ obs_difference, color = "red" ) %>% 
  gf_label(500 ~ obs_difference, label = "Observed\n Bias", 
           show.legend = FALSE) 

mean(~ M<= obs_difference, data = null_dist)

```

We see that the artificial data can hardly ever ($p = 0.0022$) mimic
what the real world experiment is showing. Hence we had good reason to
reject our NULL Hypothesis that there is no bias.

### Code

We should now repeat the test with permutations on `Education`:

```{r}

# Set graph theme
theme_set(new = theme_custom())
#

null_chisq <- do(9999) * 
  chisq.test(mosaic::tally(DeathPenalty ~ shuffle(Education), 
                   data = gss2002))

head(null_chisq)

gf_histogram( ~ X.squared, data = null_chisq) %>% 
  
  gf_vline(xintercept = observedChi2, 
           color = "red") 

prop1(~ X.squared >= observedChi2, data = null_chisq)

```

The `p-value` is well below our threshold of $0.05$, so we would
conclude that `Education` has a significant effect on `DeathPenalty`
opinion!
:::

## {{< iconify grommet-icons test >}} {{< iconify lucide ratio >}} Inference for Proportions Case Study-2: TBD dataset

To be Written Up.

## {{< iconify fluent-mdl2 decision-solid >}} Conclusion

In our basic $X^2$ test, we calculate the test statistic of $X^2$ and
look up a *theoretical* null distribution for that statistic, and see
how unlikely our observed value is.

Why would a permutation test be a good idea here? With a permutation
test, there are *no assumptions* of the null distribution: this is
computed based on real data. We note in passing that, in this case,
since the number of `cases` in each cell of the Contingency Table are
fairly high ( \>= 5) the resulting NULL distribution is of the $X^2$
variety.

## {{< iconify mingcute thought-line >}} Wait, But Why?

## {{< iconify bi person-up >}} Your Turn

## {{< iconify ooui references-rtl >}} References

1.  [OpenIntro Modern Statistics: Chapter
    17](https://openintro-ims.netlify.app/inference-one-prop.html)\

2.  Chapter 8: The Chi-Square Test, from *Statistics at Square One*. The
    British Medical Journal.
    <https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests>.
    Very readable and easy to grasp. Especially if you like watching
    [Grey's
    Anatomy](https://www.hotstar.com/in/shows/greys-anatomy/14823) and
    [House](https://www.imdb.com/title/tt0412142/).

3.  Exploring the underlying theory of the chi-square test through
    simulation - part 1
    <https://www.rdatagen.net/post/a-little-intuition-and-simulation-behind-the-chi-square-test-of-independence/>\

4.  Exploring the underlying theory of the chi-square test through
    simulation - part 2
    <https://www.rdatagen.net/post/a-little-intuition-and-simulation-behind-the-chi-square-test-of-independence-part-2/>\

5.  An Online $\Xi^2$-test calculator.
    <https://www.statology.org/chi-square-test-of-independence-calculator/>

6.  <https://saylordotorg.github.io/text_introductory-statistics/s13-04-comparison-of-two-population-p.html>

::: {#refs style="font-size: 60%;"}
###### {{< iconify lucide package-check >}} R Package Citations

```{r}
#| echo: false
#scan_packages()
cite_packages(
  output = "table",
  out.dir = ".",
  out.format = "html",
  pkgs = c("ggmosaic", "resampledata", "scales",
           "vcd")
) %>%
  knitr::kable(format = "simple")

```
:::
