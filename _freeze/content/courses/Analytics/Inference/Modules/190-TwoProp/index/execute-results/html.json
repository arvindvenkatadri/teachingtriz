{
  "hash": "092f71069463a7f657290c59c6feaeaa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"\\U0001F0CF Inference Test for Two Proportions\"\nauthor: \"Arvind V.\"\ndate: 10/Nov/2022\nabstract: \"Inference Test for Two Proportions\"\nlastmod: \"2025-06-14\"\norder: 190\nimage: preview.jpg\nimage-alt: From The Internet Archive\ncategories:\n- Permutation\n- Monte Carlo Simulation\n- Random Number Generation\n- Distributions\n- Generating Parallel Worlds\nbibliography: \n  - grateful-refs.bib\ncitation: true\n#suppress-bibliography: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n## {{< iconify noto-v1 package >}} Setting up R packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(ggmosaic) # plotting mosaic plots for Categorical Data\n\n### Dataset from Chihara and Hesterberg's book (Second Edition)\nlibrary(resampledata)\nlibrary(vcd)\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n#### Plot Theme\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# https://stackoverflow.com/questions/74491138/ggplot-custom-fonts-not-working-in-quarto\n\n# Chunk options\nknitr::opts_chunk$set(\n  fig.width = 7,\n  fig.asp = 0.618, # Golden Ratio\n  # out.width = \"80%\",\n  fig.align = \"center\"\n)\n### Ggplot Theme\n### https://rpubs.com/mclaire19/ggplot2-custom-themes\n\ntheme_custom <- function() {\n  font <- \"Roboto Condensed\" # assign font family up front\n\n  theme_classic(base_size = 14) %+replace% # replace elements we want to change\n\n    theme(\n      panel.grid.minor = element_blank(), # strip minor gridlines\n      text = element_text(family = font),\n      # text elements\n      plot.title = element_text( # title\n        family = font, # set font family\n        # size = 20,               #set font size\n        face = \"bold\", # bold typeface\n        hjust = 0, # left align\n        # vjust = 2                #raise slightly\n        margin = margin(0, 0, 10, 0)\n      ),\n      plot.subtitle = element_text( # subtitle\n        family = font, # font family\n        # size = 14,                #font size\n        hjust = 0,\n        margin = margin(2, 0, 5, 0)\n      ),\n      plot.caption = element_text( # caption\n        family = font, # font family\n        size = 8, # font size\n        hjust = 1\n      ), # right align\n\n      axis.title = element_text( # axis titles\n        family = font, # font family\n        size = 10 # font size\n      ),\n      axis.text = element_text( # axis text\n        family = font, # axis family\n        size = 8\n      ) # font size\n    )\n}\n\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n```\n:::\n\n\n:::: {.pa4}\n::: {.athelas .ml0 .mt0 .pl4 .black-90 .bl .bw2 .b--blue}\n[Early in life I had to choose between honest arrogance and hypocritical humility. I chose the former and have seen no reason to change.]{.f5 .f4-m .f3-l .lh-copy .measure .mt0}\n\n[ --- Frank Lloyd Wright]{.f6 .ttu .tracked .fs-normal}\n:::\n::::\n\n\n## {{< iconify openmoji japanese-symbol-for-beginner >}} Introduction\n\nMany experiments gather qualitative data across different segments of a\npopulation, for example, opinion about a topic among people who belong to\ndifferent income groups, or who live in different parts of a city. This\nshould remind us of the [Likert\nPlots](../../../Descriptive/Modules/45-SurveyData/index.qmd) that we\nplotted earlier. In this case the two variables, dependent and\nindependent, are both Qualitative, and we can calculate [counts and\nproportions](../../../Descriptive/Modules/40-CatData/index.qmd).\n\nHow does one Qual variable affect the other? How do counts/proportions\nof the `dependent variable` vary with the `levels` of the `independent`\nvariable? This is our task for this module.\n\nHere is a quick example of the kind of data we might look at here, taken\nfrom the [British Medical\nJournal](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests):\n\n![Breast\nFeeding](../../../../../materials/images/table-83.webp){#fig-breast-feeding}\n\nClearly, we can see differences in [counts/proportions of women who\nbreast-fed their babies for three months or more]{.black .bg-pink}, ***based on*** whether\nthey were [\"printers wives\" or \"farmers' wives\"]{.black .bg-green}! \n\nIs there a doctor in the\n[House](https://www.imdb.com/title/tt0412142/)?\n\n### {{< iconify flat-color-icons workflow >}} The CLT for Two Proportions\n\nWe first need to establish some model assumptions prior to making our\nanalysis. As before, we wish to see if the CLT applies here, and if so,\nin what form. The difference between two proportions $\\hat{p_1}-\\hat{p_2}$ can be modeled using a normal distribution when:\n\n-   **Independence (extended)**: The data are independent within and between\n    the two groups. Generally this is satisfied if the data come from\n    two independent random samples or if the data come from a randomized\n    experiment.\n-   **Success-failure condition**: The success-failure condition holds\n    for both groups, where we check successes and failures in each group\n    separately. That is, we should have at least 10 successes and 10\n    failures in each of the two groups.\n\nWhen these conditions are satisfied, the standard error of\n$\\hat{p_1}-\\hat{p_2}$ is well-approximated by:\n\n$$\nSE(\\hat{p_1}-\\hat{p_2}) = \\sqrt{\\frac{\\hat{p_1}*(1-\\hat{p_1})}{n_1}} + \\sqrt{\\frac{\\hat{p_2}*(1-\\hat{p_2})}{n_2}}\n$$\n\nwhere $\\hat{p_1}$ and $\\hat{p_2}$ represent the sample proportions, and\n$n_1$ and $n_2$ represent the sample sizes.\n\nWe can represent the Confidence Intervals as:\n\n$$\n\\begin{eqnarray}\nCI(p_1 - p_2) &=& (\\hat{p_1} - \\hat{p_2}) \\pm 1.96 * SE(\\hat{p_1}-\\hat{p_2})\\\\\n&=& (\\hat{p_1} - \\hat{p_2}) \\pm 1.96 * \\left(\\sqrt{\\frac{\\hat{p_1}*(1-\\hat{p_1})}{n_1}} + \\sqrt{\\frac{\\hat{p_2}*(1-\\hat{p_2})}{n_2}}\\right)\n\\end{eqnarray}\n$$\n\n## {{< iconify grommet-icons test >}} {{< iconify lucide ratio >}} Case Study-1: `GSS2002` dataset\n\nWe saw how we could perform inference for a single proportion. We can\nextend this idea to *multiple proportions* too.\n\nLet us try a dataset with Qualitative / Categorical data. This is the\n`General Social Survey GSS dataset` from the [`resampledata`\npackage](https://github.com/rudeboybert/resampledata), and we have\npeople with different levels of `Education` stating their opinion on the\n`Death Penalty`. We want to know if these two Categorical variables have\na correlation, i.e. can the opinions in favour of the `Death Penalty` be\nexplained by the `Education` level?\n\nSince data is Categorical ( both variables ), we need to take `counts`\nin a table, and then implement a `chi-square test`. In the test, we will\npermute the `Education` variable to see if we can see how significant\nits *effect size* is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(GSS2002, package = \"resampledata\")\nglimpse(GSS2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,765\nColumns: 21\n$ ID            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ Region        <fct> South Central, South Central, South Central, South Centr…\n$ Gender        <fct> Female, Male, Female, Female, Male, Male, Female, Female…\n$ Race          <fct> White, White, White, White, White, White, White, White, …\n$ Education     <fct> HS, Bachelors, HS, Left HS, Left HS, HS, Bachelors, HS, …\n$ Marital       <fct> Divorced, Married, Separated, Divorced, Divorced, Divorc…\n$ Religion      <fct> Inter-nondenominational, Protestant, Protestant, Protest…\n$ Happy         <fct> Pretty happy, Pretty happy, NA, NA, NA, Pretty happy, NA…\n$ Income        <fct> 30000-34999, 75000-89999, 35000-39999, 50000-59999, 4000…\n$ PolParty      <fct> \"Strong Rep\", \"Not Str Rep\", \"Strong Rep\", \"Ind, Near De…\n$ Politics      <fct> Conservative, Conservative, NA, NA, NA, Conservative, NA…\n$ Marijuana     <fct> NA, Not legal, NA, NA, NA, NA, NA, NA, Legal, NA, NA, NA…\n$ DeathPenalty  <fct> Favor, Favor, NA, NA, NA, Favor, NA, NA, Favor, NA, NA, …\n$ OwnGun        <fct> No, Yes, NA, NA, NA, Yes, NA, NA, Yes, NA, NA, NA, NA, N…\n$ GunLaw        <fct> Favor, Oppose, NA, NA, NA, Oppose, NA, NA, Oppose, NA, N…\n$ SpendMilitary <fct> Too little, About right, NA, About right, NA, Too little…\n$ SpendEduc     <fct> Too little, Too little, NA, Too little, NA, Too little, …\n$ SpendEnv      <fct> About right, About right, NA, Too little, NA, Too little…\n$ SpendSci      <fct> About right, About right, NA, Too little, NA, Too little…\n$ Pres00        <fct> Bush, Bush, Bush, NA, NA, Bush, Bush, Bush, Bush, NA, NA…\n$ Postlife      <fct> Yes, Yes, NA, NA, NA, Yes, NA, NA, Yes, NA, NA, NA, NA, …\n```\n\n\n:::\n\n```{.r .cell-code}\ninspect(GSS2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\ncategorical variables:  \n            name  class levels    n missing\n1         Region factor      7 2765       0\n2         Gender factor      2 2765       0\n3           Race factor      3 2765       0\n4      Education factor      5 2760       5\n5        Marital factor      5 2765       0\n6       Religion factor     13 2746      19\n7          Happy factor      3 1369    1396\n8         Income factor     24 1875     890\n9       PolParty factor      8 2729      36\n10      Politics factor      7 1331    1434\n11     Marijuana factor      2  851    1914\n12  DeathPenalty factor      2 1308    1457\n13        OwnGun factor      3  924    1841\n14        GunLaw factor      2  916    1849\n15 SpendMilitary factor      3 1324    1441\n16     SpendEduc factor      3 1343    1422\n17      SpendEnv factor      3 1322    1443\n18      SpendSci factor      3 1266    1499\n19        Pres00 factor      5 1749    1016\n20      Postlife factor      2 1211    1554\n                                    distribution\n1  North Central (24.7%) ...                    \n2  Female (55.6%), Male (44.4%)                 \n3  White (79.1%), Black (14.8%) ...             \n4  HS (53.8%), Bachelors (16.1%) ...            \n5  Married (45.9%), Never Married (25.6%) ...   \n6  Protestant (53.2%), Catholic (24.5%) ...     \n7  Pretty happy (57.3%) ...                     \n8  40000-49999 (9.1%) ...                       \n9  Ind (19.3%), Not Str Dem (18.9%) ...         \n10 Moderate (39.2%), Conservative (15.8%) ...   \n11 Not legal (64%), Legal (36%)                 \n12 Favor (68.7%), Oppose (31.3%)                \n13 No (65.5%), Yes (33.5%) ...                  \n14 Favor (80.5%), Oppose (19.5%)                \n15 About right (46.5%) ...                      \n16 Too little (73.9%) ...                       \n17 Too little (60%) ...                         \n18 About right (49.7%) ...                      \n19 Bush (50.6%), Gore (44.7%) ...               \n20 Yes (80.5%), No (19.5%)                      \n\nquantitative variables:  \n  name   class min  Q1 median   Q3  max mean       sd    n missing\n1   ID integer   1 692   1383 2074 2765 1383 798.3311 2765       0\n```\n\n\n:::\n\n```{.r .cell-code}\nskimr::skim(GSS2002)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |GSS2002 |\n|Number of rows           |2765    |\n|Number of columns        |21      |\n|_______________________  |        |\n|Column type frequency:   |        |\n|factor                   |20      |\n|numeric                  |1       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                              |\n|:-------------|---------:|-------------:|:-------|--------:|:---------------------------------------|\n|Region        |         0|          1.00|FALSE   |        7|Nor: 684, Sou: 486, Sou: 471, Mid: 435  |\n|Gender        |         0|          1.00|FALSE   |        2|Fem: 1537, Mal: 1228                    |\n|Race          |         0|          1.00|FALSE   |        3|Whi: 2188, Bla: 410, Oth: 167           |\n|Education     |         5|          1.00|FALSE   |        5|HS: 1485, Bac: 443, Lef: 400, Gra: 230  |\n|Marital       |         0|          1.00|FALSE   |        5|Mar: 1269, Nev: 708, Div: 445, Wid: 247 |\n|Religion      |        19|          0.99|FALSE   |       13|Pro: 1460, Cat: 673, Non: 379, Chr: 65  |\n|Happy         |      1396|          0.50|FALSE   |        3|Pre: 784, Ver: 415, Not: 170            |\n|Income        |       890|          0.68|FALSE   |       24|400: 170, 300: 166, 250: 140, 500: 136  |\n|PolParty      |        36|          0.99|FALSE   |        8|Ind: 528, Not: 515, Not: 449, Str: 408  |\n|Politics      |      1434|          0.48|FALSE   |        7|Mod: 522, Con: 210, Sli: 209, Sli: 159  |\n|Marijuana     |      1914|          0.31|FALSE   |        2|Not: 545, Leg: 306                      |\n|DeathPenalty  |      1457|          0.47|FALSE   |        2|Fav: 899, Opp: 409                      |\n|OwnGun        |      1841|          0.33|FALSE   |        3|No: 605, Yes: 310, Ref: 9               |\n|GunLaw        |      1849|          0.33|FALSE   |        2|Fav: 737, Opp: 179                      |\n|SpendMilitary |      1441|          0.48|FALSE   |        3|Abo: 615, Too: 414, Too: 295            |\n|SpendEduc     |      1422|          0.49|FALSE   |        3|Too: 992, Abo: 278, Too: 73             |\n|SpendEnv      |      1443|          0.48|FALSE   |        3|Too: 793, Abo: 439, Too: 90             |\n|SpendSci      |      1499|          0.46|FALSE   |        3|Abo: 629, Too: 461, Too: 176            |\n|Pres00        |      1016|          0.63|FALSE   |        5|Bus: 885, Gor: 781, Nad: 57, Oth: 16    |\n|Postlife      |      1554|          0.44|FALSE   |        2|Yes: 975, No: 236                       |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|     sd| p0| p25|  p50|  p75| p100|hist  |\n|:-------------|---------:|-------------:|----:|------:|--:|---:|----:|----:|----:|:-----|\n|ID            |         0|             1| 1383| 798.33|  1| 692| 1383| 2074| 2765|▇▇▇▇▇ |\n\n\n:::\n:::\n\n\n<br>\n\nNote how *all* variables are Categorical !! `Education` has five\n`levels`, and of course `DeathPenalty` has three:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGSS2002 %>% count(Education)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Education\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"5\"},{\"1\":\"Left HS\",\"2\":\"400\"},{\"1\":\"HS\",\"2\":\"1485\"},{\"1\":\"Jr Col\",\"2\":\"202\"},{\"1\":\"Bachelors\",\"2\":\"443\"},{\"1\":\"Graduate\",\"2\":\"230\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nGSS2002 %>% count(DeathPenalty)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"DeathPenalty\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"1457\"},{\"1\":\"Favor\",\"2\":\"899\"},{\"1\":\"Oppose\",\"2\":\"409\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nLet us drop NA entries in `Education` and `Death Penalty` and set up a\n[**Contingency\nTable**](../../../Descriptive/Modules/40-CatData/index.qmd#what-is-a-contingency-table).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss2002 <- GSS2002 %>%\n  dplyr::select(Education, DeathPenalty) %>%\n  tidyr::drop_na(., c(Education, DeathPenalty))\n##\ngss_table <- mosaic::tally(DeathPenalty ~ Education, data = gss2002) %>%\n  addmargins()\ngss_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Education\nDeathPenalty Left HS   HS Jr Col Bachelors Graduate  Sum\n      Favor      117  511     71       135       64  898\n      Oppose      72  200     16        71       50  409\n      Sum        189  711     87       206      114 1307\n```\n\n\n:::\n:::\n\n\n### Contingency Table Plots\n\nThe Contingency Table can be plotted, as we have seen, using a\n`mosaic`plot using several packages. Let us do a quick recap:\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n\n#### Using vcd\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmosaic::tally(DeathPenalty ~ Education, data = gss2002) %>%\n  vcd::mosaic(gp = shading_hsv)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=2100}\n:::\n:::\n\n\n#### Using ggmosaic\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(ggmosaic)\n\n# Set graph theme\ntheme_set(new = theme_custom())\n#\nggplot(data = gss2002) +\n  geom_mosaic(aes(\n    x = product(DeathPenalty, Education),\n    fill = DeathPenalty\n  ))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/mosaic-plot-1.png){width=2100}\n:::\n:::\n\n\n#### Using ggformula\n\nAs seen before, it needs a little more work, to convert the Contingency\nTable into a tibble:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://stackoverflow.com/questions/19233365/how-to-create-a-marimekko-mosaic-plot-in-ggplot2\n\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\ngss_summary <- gss2002 %>%\n  mutate(\n    Education = factor(\n      Education,\n      levels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\"),\n      labels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\")\n    ),\n    DeathPenalty = as.factor(DeathPenalty)\n  ) %>%\n  group_by(Education, DeathPenalty) %>%\n  summarise(count = n()) %>% # This is good for a chisq test\n\n  # Add two more columns to facilitate mosaic/Marrimekko Plot\n  mutate(\n    edu_count = sum(count),\n    edu_prop = count / sum(count)\n  ) %>%\n  ungroup()\n###\ngf_col(edu_prop ~ Education,\n  data = gss_summary,\n  width = ~edu_count,\n  fill = ~DeathPenalty,\n  stat = \"identity\",\n  position = \"fill\",\n  color = \"black\"\n) %>%\n  gf_text(edu_prop ~ Education,\n    label = ~ scales::percent(edu_prop),\n    position = position_stack(vjust = 0.5)\n  ) %>%\n  gf_facet_grid(~Education,\n    scales = \"free_x\",\n    space = \"free_x\"\n  ) %>%\n  gf_theme(scale_fill_manual(values = c(\"orangered\", \"palegreen3\")))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=2100}\n:::\n:::\n\n:::\n\n## Hypotheses Definition\n\nWhat would our Hypotheses be relating to the *proportions* of votes for or against the Death Penalty?\n\n$H_0: \\text{Education does not affect votes for Death Penalty}\\\\$\n\n$H_a: \\text{Education affects votes for Death Penalty}\\\\$\n\n## Inference for Two Proportions\n\nWe are now ready to perform our statistical inference. We will use the\nstandard `Pearson chi-square test`, and develop and intuition for it. We\nwill then do a permutation test to have an alternative method to\ncomplete the same task.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### Code\n\nLet us now perform the base `chisq test`: We need a `contingency table` and then the `chisq` test: We will calculate the `observed-chi-squared` value, and compare it with the `critical value`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Chi-square test\nmosaic::xchisq.test(mosaic::tally(DeathPenalty ~ Education, data = gss2002))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  x\nX-squared = 23.451, df = 4, p-value = 0.0001029\n\n  117      511       71      135       64   \n(129.86) (488.51) ( 59.78) (141.54) ( 78.33)\n [1.27]   [1.04]   [2.11]   [0.30]   [2.62] \n<-1.13>  < 1.02>  < 1.45>  <-0.55>  <-1.62> \n         \n   72      200       16       71       50   \n( 59.14) (222.49) ( 27.22) ( 64.46) ( 35.67)\n [2.79]   [2.27]   [4.63]   [0.66]   [5.75] \n< 1.67>  <-1.51>  <-2.15>  < 0.81>  < 2.40> \n         \nkey:\n\tobserved\n\t(expected)\n\t[contribution to X-squared]\n\t<Pearson residual>\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get the observed chi-square statistic\nobservedChi2 <- mosaic::chisq(mosaic::tally(DeathPenalty ~ Education, data = gss2002))\nobservedChi2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nX.squared \n 23.45093 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Determine the Chi-Square critical value\nX_squared_critical <- qchisq(\n  p = .05,\n  df = (5 - 1) * (2 - 1), # (nrows-1) * (ncols-1)\n  lower.tail = FALSE\n)\nX_squared_critical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.487729\n```\n\n\n:::\n:::\n\n\nWe see that our observed $X^2 = 23.45$; the critical value\n`X_squared_critical` is $9.48$, which is much smaller! The `p-value` is\n$0.0001029$, very low as we would expect, indicating that the NULL\nHypothesis should be rejected in favour of the alternate hypothesis,\nthat opinions about the `DeathPenalty` are related to `Education`.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nVerbose output not yet implemented.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=2100}\n:::\n:::\n\n\nLet us now dig into that cryptic-looking table above!\n\n### Intuitive Explanation\n\nLet us look at the Contingency Table that we have:\n\n\n::: {.cell}\n::: {#fig-sample-contingency-table-picture .cell-output-display}\n\n```{=html}\n<!-- preamble start -->\n\n    <script>\n\n      function styleCell_561au0dq75v1tgwdbmxm(i, j, css_id) {\n          var table = document.getElementById(\"tinytable_561au0dq75v1tgwdbmxm\");\n          var cell = table.rows[i]?.cells[j];  // Safe navigation to avoid errors\n          if (cell) {\n              console.log(`Styling cell at (${i}, ${j}) with class ${css_id}`);\n              cell.classList.add(css_id);\n          } else {\n              console.warn(`Cell at (${i}, ${j}) not found.`);\n          }\n      }\n      function insertSpanRow(i, colspan, content) {\n        var table = document.getElementById('tinytable_561au0dq75v1tgwdbmxm');\n        var newRow = table.insertRow(i);\n        var newCell = newRow.insertCell(0);\n        newCell.setAttribute(\"colspan\", colspan);\n        // newCell.innerText = content;\n        // this may be unsafe, but innerText does not interpret <br>\n        newCell.innerHTML = content;\n      }\n      function spanCell_561au0dq75v1tgwdbmxm(i, j, rowspan, colspan) {\n        var table = document.getElementById(\"tinytable_561au0dq75v1tgwdbmxm\");\n        const targetRow = table.rows[i];\n        const targetCell = targetRow.cells[j];\n        for (let r = 0; r < rowspan; r++) {\n          // Only start deleting cells to the right for the first row (r == 0)\n          if (r === 0) {\n            // Delete cells to the right of the target cell in the first row\n            for (let c = colspan - 1; c > 0; c--) {\n              if (table.rows[i + r].cells[j + c]) {\n                table.rows[i + r].deleteCell(j + c);\n              }\n            }\n          }\n          // For rows below the first, delete starting from the target column\n          if (r > 0) {\n            for (let c = colspan - 1; c >= 0; c--) {\n              if (table.rows[i + r] && table.rows[i + r].cells[j]) {\n                table.rows[i + r].deleteCell(j);\n              }\n            }\n          }\n        }\n        // Set rowspan and colspan of the target cell\n        targetCell.rowSpan = rowspan;\n        targetCell.colSpan = colspan;\n      }\n      // tinytable span after\n      window.addEventListener('load', function () {\n          var cellsToStyle = [\n            // tinytable style arrays after\n          { positions: [ { i: 1, j: 1 }, { i: 2, j: 4 },  ], css_id: 'tinytable_css_zkny738p88pu2z00z190',}, \n          { positions: [ { i: 3, j: 0 }, { i: 3, j: 1 }, { i: 3, j: 2 }, { i: 3, j: 3 }, { i: 3, j: 4 }, { i: 3, j: 5 }, { i: 3, j: 6 },  ], css_id: 'tinytable_css_7kr1fk1yq5y2px7g84s5',}, \n          { positions: [ { i: 1, j: 0 }, { i: 2, j: 0 }, { i: 1, j: 2 }, { i: 2, j: 1 }, { i: 1, j: 3 }, { i: 2, j: 2 }, { i: 1, j: 4 }, { i: 2, j: 3 }, { i: 1, j: 5 }, { i: 2, j: 5 }, { i: 1, j: 6 }, { i: 2, j: 6 },  ], css_id: 'tinytable_css_ij73gf1vj3ca9agaqvv5',}, \n          { positions: [ { i: 0, j: 0 }, { i: 0, j: 1 }, { i: 0, j: 2 }, { i: 0, j: 3 }, { i: 0, j: 4 }, { i: 0, j: 5 }, { i: 0, j: 6 },  ], css_id: 'tinytable_css_o0dmg8wcubmd51mdan1e',}, \n          ];\n\n          // Loop over the arrays to style the cells\n          cellsToStyle.forEach(function (group) {\n              group.positions.forEach(function (cell) {\n                  styleCell_561au0dq75v1tgwdbmxm(cell.i, cell.j, group.css_id);\n              });\n          });\n      });\n    </script>\n\n    <style>\n      /* tinytable css entries after */\n      .table td.tinytable_css_zkny738p88pu2z00z190, .table th.tinytable_css_zkny738p88pu2z00z190 { color: grey; font-weight: bold; color: black; background-color: yellow; }\n      .table td.tinytable_css_7kr1fk1yq5y2px7g84s5, .table th.tinytable_css_7kr1fk1yq5y2px7g84s5 { color: grey; font-weight: bold; color: black; background-color: palegreen; border-bottom: solid #d3d8dc 0.1em; }\n      .table td.tinytable_css_ij73gf1vj3ca9agaqvv5, .table th.tinytable_css_ij73gf1vj3ca9agaqvv5 { color: grey; }\n      .table td.tinytable_css_o0dmg8wcubmd51mdan1e, .table th.tinytable_css_o0dmg8wcubmd51mdan1e { color: grey; border-top: solid #d3d8dc 0.1em; border-bottom: solid #d3d8dc 0.05em; }\n    </style>\n    <div class=\"container\">\n      <table class=\"table table-borderless\" id=\"tinytable_561au0dq75v1tgwdbmxm\" style=\"width: auto; margin-left: auto; margin-right: auto;\" data-quarto-disable-processing='true'>\n        <thead>\n        \n              <tr>\n                <th scope=\"col\">DeathPenalty</th>\n                <th scope=\"col\">Left HS</th>\n                <th scope=\"col\">HS</th>\n                <th scope=\"col\">Jr Col</th>\n                <th scope=\"col\">Bachelors</th>\n                <th scope=\"col\">Graduate</th>\n                <th scope=\"col\">Sum</th>\n              </tr>\n        </thead>\n        \n        <tbody>\n                <tr>\n                  <td>Favor</td>\n                  <td>117</td>\n                  <td>511</td>\n                  <td>71</td>\n                  <td>135</td>\n                  <td>64</td>\n                  <td>898</td>\n                </tr>\n                <tr>\n                  <td>Oppose</td>\n                  <td>72</td>\n                  <td>200</td>\n                  <td>16</td>\n                  <td>71</td>\n                  <td>50</td>\n                  <td>409</td>\n                </tr>\n                <tr>\n                  <td>Sum</td>\n                  <td>189</td>\n                  <td>711</td>\n                  <td>87</td>\n                  <td>206</td>\n                  <td>114</td>\n                  <td>1307</td>\n                </tr>\n        </tbody>\n      </table>\n    </div>\n<!-- hack to avoid NA insertion in last line -->\n```\n\n\nContingency Table\n:::\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n<br> In the chi-square test, we check whether the two (or more)\ncategorical variables are independent. To do this we perform a simple\ncheck on the Contingency Table. We first *re-compute* the totals in each\nrow and column, based on what we could **expect** ***if there was\nindependence (NULL Hypothesis)***. If the two variables were independent,\nthen there should be **no difference** between real and expected scores.\n\nHow do we know [what scores to expect]{.black .bg-light-red} if there was\nno relationship between the variables?\n\nConsider the entry in location (1,1): 117. The number of **expected**\nentries there is the *probability of an entry landing in that square*\ntimes *the total number of entries*:\n\n$$\n\\begin{align}\n\\text{Expected Value[1,1]}\n&= p_{row_1} * p_{col_1} * Total~Scores\\\\\\\n&= \\Large{\\frac{\\sum_{r_{1}}}{\\sum_{r_{all}c_{all}}} * \\frac{\\sum_{c_{1}}}{\\sum_{r_{all}c_{all}}} * \\sum_{r_{all}c_{all}}} \\\\\n&= \\frac{898}{1307} * \\frac{189}{1307} * 1307\\\\\\\n&= 130\n\\end{align}\n$$\n\nProceeding in this way for all the 15 entries in the Contingency Table,\nwe get the \"Expected\" Contingency Table. Here are both tables for\ncomparison:\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Expected Contingency Table</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Left HS </th>\n   <th style=\"text-align:right;\"> HS </th>\n   <th style=\"text-align:right;\"> Jr Col </th>\n   <th style=\"text-align:right;\"> Bachelors </th>\n   <th style=\"text-align:right;\"> Graduate </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Favor </td>\n   <td style=\"text-align:right;\"> 130 </td>\n   <td style=\"text-align:right;\"> 489 </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 142 </td>\n   <td style=\"text-align:right;\"> 78 </td>\n   <td style=\"text-align:right;\"> 898 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Oppose </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 222 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 36 </td>\n   <td style=\"text-align:right;\"> 409 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 189 </td>\n   <td style=\"text-align:right;\"> 711 </td>\n   <td style=\"text-align:right;\"> 87 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 114 </td>\n   <td style=\"text-align:right;\"> 1307 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Actual Contingency Table</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Left HS </th>\n   <th style=\"text-align:right;\"> HS </th>\n   <th style=\"text-align:right;\"> Jr Col </th>\n   <th style=\"text-align:right;\"> Bachelors </th>\n   <th style=\"text-align:right;\"> Graduate </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Favor </td>\n   <td style=\"text-align:right;\"> 117 </td>\n   <td style=\"text-align:right;\"> 511 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 135 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 898 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Oppose </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 200 </td>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 50 </td>\n   <td style=\"text-align:right;\"> 409 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 189 </td>\n   <td style=\"text-align:right;\"> 711 </td>\n   <td style=\"text-align:right;\"> 87 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 114 </td>\n   <td style=\"text-align:right;\"> 1307 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAnd here are the mosaic plots for the *actual* and *expected* Contingency Tables, along with the *association* plot showing the differences, as we did when plotting [Proportions](../../../Descriptive/Modules/40-CatData/index.qmd#coloured-tiles-actual-and-expected-contingency-tables):\n\n\n\n::: {.cell layout-ncol=\"3\"}\n::: {.cell-output-display}\n![Actual](index_files/figure-html/unnamed-chunk-12-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![Expected](index_files/figure-html/unnamed-chunk-12-2.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![Tile-Wise Differences](index_files/figure-html/unnamed-chunk-12-3.png){width=2100}\n:::\n:::\n\n\n<br> \n\nNow, the **Pearson Residual** in each cell is equivalent to the\n`z-score` of that cell. Recall the [z-score](../22-Histograms/index.qmd#z-scores) idea: we subtract the mean and divide by the std. deviation to get the `z-score`.\n\nIn the Contingency Table, we have **counts** which are usually modeled\nas an (integer) *Poisson distribution*, for which **mean (i.e Expected\nvalue) and variance are identical**. Thus we get the Pearson Residual\nas:\n\n$$\nr_{i,j} = \\frac{(Actual - Expected)}{\\sqrt{\\displaystyle Expected}}\n$$ \n\nand therefore:\n\n\n$$\nr_{i,j} = \\frac{(o_{i,j}- e_{i,j})}{\\sqrt{\\displaystyle e_{i,j}}}\n$$\n\n\nThe sum of all the squared Pearson residuals is the chi-square\nstatistic, χ2, upon which the inferential analysis follows. \n\n$$\nχ2 = \\sum_{i=1}^R\\sum_{j=1}^C{r_{i,j}^2} \n$$ \n\n\nwhere R and C are number of rows and columns in the Contingency\nTable, the levels in the two Qual variables.\n\nFor location \\[1,1\\], its contribution to χ2 would be: $(117-130)^2/130 = 1.3$. \nDo try to compute all of these and the $X^2$ statistic by hand !!\n\nAll right, what of all this? How did this $X^2$ distribution come from?\nHere is a lovely, brief explanation from this [StackOverflow\nPost](https://stats.stackexchange.com/a/303548):\n\n> -   In a Contingency Table the Null Hypothesis states that the\n>     variables in the rows and the variable in the columns are\n>     independent.\\\n> -   The cell counts $E_{ij}$ are assumed to be [Poisson distributed]{.bg-light-red .black} with mean = $E_{ij}$ and as they are Poisson, their variance is\n>     also $E_{ij}$.\\\n> -   Asymptotically the Poisson distribution approaches the [normal\n>     distribution]{.bg-light-red .black}, with mean = $E_{ij}$ and *standard deviation* with\n>     $\\sqrt{E_{ij}}$ so, asymptotically\n>     $\\large{\\frac{(X_{ij} - E_{ij})}{\\sqrt{E_{ij}}}}$ is approximately\n>     standard normal $N(0,1)$.\\\n> -   If you square standard normal variables and sum these squares then\n>     the result is a chi-square random variable so\n>     $\\sum_{i,j}\\left(\\frac{(X_{ij}-E_{ij})}{\\sqrt{E_{ij}}}\\right)^2$\n>     has a (asymptotically) a [chi-square\n>     distribution]{.bg-light-red .black}.\\\n> -   Asymptotics must hold and that is why most textbooks state that\n>     the result of the test is valid when all expected cell counts\n>     $E_{ij}$ are larger than 5, but that is just a rule of thumb that\n>     makes the approximation ''good enough''.\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-2.png){width=2100}\n:::\n:::\n\n:::\n\n\n## Permutation Test for `Education`\n\nWe will now perform the permutation test for the difference between\nproportions. We will first get an intuitive idea of the permutation, and\nthen perform it using both `mosaic` and `infer`.\n\n::: {.panel-tabset .nav-pills style=\"background: whitesmoke;\"}\n### {{< iconify svg-spinners blocks-shuffle-3 >}} Permutation Visually Demonstrated\n\nWe saw from the diagram created by Allen Downey that [there is only one\ntest](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)!\nWe will now use this philosophy to develop a technique that allows us to\nmechanize several *Statistical Models* in that way, with nearly\nidentical code. We will first look visually at a permutation exercise.\nWe will create dummy data that contains the following case study:\n\n> A set of identical resumes was sent to male and female evaluators. The\n> candidates in the resumes were of both genders. We wish to see if\n> there was difference in the way resumes were evaluated, by male and\n> female evaluators. (We use just *one* male and *one* female evaluator\n> here, to keep things simple!)\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"evaluator\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"candidate_selected\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"0\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"0\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"0\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"F\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"1\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"0\"},{\"1\":\"M\",\"2\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"evaluator\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"selection_ratio\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"count\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"F\",\"2\":\"0.1250000\",\"3\":\"3\",\"4\":\"24\"},{\"1\":\"M\",\"2\":\"0.4583333\",\"3\":\"11\",\"4\":\"24\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n::: {.cell layout=\"[20,80]\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n         M \n-0.3333333 \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/Difference in Proportion-1.png){width=2100}\n:::\n:::\n\nSo, we have a solid disparity in percentage of selection between the two\nevaluators! Now we pretend that *there is no difference between the\nselections made by either set of evaluators*. So we can just:\n\n-   Pool up all the evaluations\\\n-   Arbitrarily re-assign a given candidate(selected or rejected) to\n    either of the two sets of evaluators, by permutation.\\\n\nHow would that pooled shuffled set of evaluations look like?\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"selection_ratio\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"count\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.2916667\",\"2\":\"14\",\"3\":\"48\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n::: {.cell layout=\"[[45,-10,45]]\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=2100}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-2.png){width=2100}\n:::\n:::\n\n\n::: {.cell}\n\n:::\n\nAs can be seen, the ratio is different!\n\nWe can now check out our Hypothesis that there is *no* bias. We can\nshuffle the data many many times, calculating the ratio each time, and\nplot the *distribution of the differences in selection ratio* and see\nhow that artificially created distribution compares with the originally\nobserved figure from Mother Nature.\n\n\n::: {.cell layout=\"[[60,-10,30]]\"}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\nnull_dist <- do(4999) * diff(mean(\n  candidate_selected ~ shuffle(evaluator),\n  data = data\n))\n# null_dist %>% names()\nnull_dist %>%\n  gf_histogram(~M,\n    fill = ~ (M <= obs_difference),\n    bins = 25, show.legend = FALSE,\n    xlab = \"Bias Proportion\",\n    ylab = \"How Often?\",\n    title = \"Permutation Test on Difference between Groups\",\n    subtitle = \"\"\n  ) %>%\n  gf_vline(xintercept = ~obs_difference, color = \"red\") %>%\n  gf_label(500 ~ obs_difference,\n    label = \"Observed\\n Bias\",\n    show.legend = FALSE\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nmean(~ M <= obs_difference, data = null_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.00220044\n```\n\n\n:::\n:::\n\n\nWe see that the artificial data can hardly ever ($p = 0.0022$) mimic\nwhat the real world experiment is showing. Hence we had good reason to\nreject our NULL Hypothesis that there is no bias.\n\n### Code\n\nWe should now repeat the test with permutations on `Education`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set graph theme\ntheme_set(new = theme_custom())\n#\n\nnull_chisq <- do(4999) *\n  chisq.test(mosaic::tally(DeathPenalty ~ shuffle(Education),\n    data = gss2002\n  ))\n\nhead(null_chisq)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"X.squared\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"alternative\"],\"name\":[5],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"data\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".row\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".index\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"12.319854\",\"2\":\"4\",\"3\":\"0.01512469\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"mosaic::tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"1\",\"_rn_\":\"X-squared...1\"},{\"1\":\"5.208442\",\"2\":\"4\",\"3\":\"0.26657081\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"mosaic::tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"2\",\"_rn_\":\"X-squared...2\"},{\"1\":\"5.431285\",\"2\":\"4\",\"3\":\"0.24583591\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"mosaic::tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"3\",\"_rn_\":\"X-squared...3\"},{\"1\":\"8.918993\",\"2\":\"4\",\"3\":\"0.06315646\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"mosaic::tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"4\",\"_rn_\":\"X-squared...4\"},{\"1\":\"1.251510\",\"2\":\"4\",\"3\":\"0.86954725\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"mosaic::tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"5\",\"_rn_\":\"X-squared...5\"},{\"1\":\"1.802120\",\"2\":\"4\",\"3\":\"0.77209444\",\"4\":\"Pearson's Chi-squared test\",\"5\":\"NA\",\"6\":\"mosaic::tally(DeathPenalty ~ shuffle(Education), data = gss2002)\",\"7\":\"1\",\"8\":\"6\",\"_rn_\":\"X-squared...6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ngf_histogram(~X.squared, data = null_chisq) %>%\n  gf_vline(\n    xintercept = observedChi2,\n    color = \"red\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=2100}\n:::\n\n```{.r .cell-code}\nprop1(~ X.squared >= observedChi2, data = null_chisq)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nprop_TRUE \n    2e-04 \n```\n\n\n:::\n:::\n\n\nThe `p-value` is well below our threshold of $0.05$, so we would\nconclude that `Education` has a significant effect on `DeathPenalty`\nopinion!\n:::\n\n## {{< iconify grommet-icons test >}} {{< iconify lucide ratio >}} Inference for Proportions Case Study-2: TBD dataset\n\nTo be Written Up.\n\n## {{< iconify fluent-mdl2 decision-solid >}} Conclusion\n\nIn our basic $X^2$ test, we calculate the test statistic of $X^2$ and\nlook up a *theoretical* null distribution for that statistic, and see\nhow unlikely our observed value is.\n\nWhy would a permutation test be a good idea here? With a permutation\ntest, there are *no assumptions* of the null distribution: this is\ncomputed based on real data. We note in passing that, in this case,\nsince the number of `cases` in each cell of the Contingency Table are\nfairly high ( \\>= 5) the resulting NULL distribution is of the $X^2$\nvariety.\n\n## {{< iconify mingcute thought-line >}} Wait, But Why?\n\n## {{< iconify bi person-up >}} Your Turn\n\n## {{< iconify ooui references-rtl >}} References\n\n1.  [OpenIntro Modern Statistics: Chapter\n    17](https://openintro-ims.netlify.app/inference-one-prop.html)\\\n\n2.  Chapter 8: The Chi-Square Test, from *Statistics at Square One*. The\n    British Medical Journal.\n    <https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/8-chi-squared-tests>.\n    Very readable and easy to grasp. Especially if you like watching\n    [Grey's\n    Anatomy](https://www.hotstar.com/in/shows/greys-anatomy/14823) and\n    [House](https://www.imdb.com/title/tt0412142/).\n\n3.  Exploring the underlying theory of the chi-square test through\n    simulation - part 1\n    <https://www.rdatagen.net/post/a-little-intuition-and-simulation-behind-the-chi-square-test-of-independence/>\\\n\n4.  Exploring the underlying theory of the chi-square test through\n    simulation - part 2\n    <https://www.rdatagen.net/post/a-little-intuition-and-simulation-behind-the-chi-square-test-of-independence-part-2/>\\\n\n5.  An Online $\\Xi^2$-test calculator.\n    <https://www.statology.org/chi-square-test-of-independence-calculator/>\n\n6.  <https://saylordotorg.github.io/text_introductory-statistics/s13-04-comparison-of-two-population-p.html>\n\n::: {#refs style=\"font-size: 60%;\"}\n###### {{< iconify lucide package-check >}} R Package Citations\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nPackage        Version   Citation                     \n-------------  --------  -----------------------------\nggmosaic       0.3.3     @ggmosaic                    \nresampledata   0.3.2     @resampledata                \nscales         1.4.0     @scales                      \nvcd            1.4.13    @vcd2006; @vcd2007; @vcd2024 \n\n\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"../../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}