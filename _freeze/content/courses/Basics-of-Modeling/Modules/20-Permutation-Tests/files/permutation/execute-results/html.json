{
  "hash": "79e29b5f389791499a6e731ea4145c72",
  "result": {
    "markdown": "---\ntitle: \"Permutation Tests\"\nauthor: \"Arvind Venkatadri\"\ndate: \"2023-01-12\"\ncode-fold: true\ncode-tools: true\ncode-line-numbers: true\ncode-copy: true\ncode-summary: \"Show the Code\"\nexecute: \n  freeze: auto\n---\n\n\n\n\n## Permutation Tests\n\n### Case Study-1: Hot Wings Orders vs Gender\n\nA student conducted a study of hot wings and beer consumption at a Bar.\nShe asked patrons at the bar to record their consumption of hot wings\nand beer over the course of several hours. She wanted to know if people\nwho ate more hot wings would then drink more beer. In addition, she\ninvestigated whether or not gender had an impact on hot wings or beer\nconsumption.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBeerwings <- read.csv(\"../../../../../materials/data/resampling/Beerwings.csv\")\ninspect(Beerwings)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n    name     class levels  n missing\n1 Gender character      2 30       0\n                                   distribution\n1 F (50%), M (50%)                             \n\nquantitative variables:  \n      name   class min    Q1 median    Q3 max     mean        sd  n missing\n1       ID integer   1  8.25   15.5 22.75  30 15.50000  8.803408 30       0\n2 Hotwings integer   4  8.00   12.5 15.50  21 11.93333  4.784554 30       0\n3     Beer integer   0 24.00   30.0 36.00  48 26.20000 11.842064 30       0\n```\n:::\n:::\n\n\nLet us calculate the observed difference in `Hotwings` consumption\nbetween Males and Females ( `Gender`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(Hotwings ~ Gender, data = Beerwings)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        F         M \n 9.333333 14.533333 \n```\n:::\n\n```{.r .cell-code}\nobs_diff_wings <- mosaic::diffmean(data = Beerwings, Hotwings ~ Gender)\nobs_diff_wings \n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndiffmean \n     5.2 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_boxplot(data = Beerwings, Hotwings ~ Gender, title = \"Hotwings Consumption by Gender\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-3-1.png){width=50% height=50%}\n:::\n:::\n\n\nThe observed difference in mean consumption of Hotwings between Males\nand Females is 5.2. Could this have occurred by chance? Here is our\nformulation of the Hypotheses:\n\n$$\nNULL\\ Hypothesis\\ H_0 => No\\ difference\\ between\\ means\\ across\\ groups\\\\\nAlternative\\ Hypothesis\\\nH_a =>Significant\\ difference\\ between\\ the\\ means\\\n$$\n\nSo we perform a Permutation Test to check:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist_wings <- do(1000) * diffmean(Hotwings ~ shuffle(Gender), data = Beerwings)\nnull_dist_wings %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    diffmean\n1 -0.2666667\n2 -1.3333333\n3 -0.2666667\n4  0.6666667\n5 -0.1333333\n6  1.2000000\n```\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_wings, ~ diffmean) %>% \n  gf_vline(xintercept = obs_diff_wings, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-4-1.png){width=50% height=50%}\n:::\n\n```{.r .cell-code}\nprop1(~ diffmean >= obs_diff_wings, data = null_dist_wings)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  prop_TRUE \n0.001998002 \n```\n:::\n:::\n\n\nThe $\\color{red}{red\\ line}$ shows the actual measured mean difference\nin Hot Wings consumption. The probability that our Permutation\ndistribution is able to equal or exceed that number is $0.001998002$ and\nwe have to reject the Null Hypothesis that the means are identical.\n\n### Case Study-2: Verizon\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverizon <- read.csv(\"../../../../../materials/data/resampling/Verizon.csv\")\ninspect(verizon)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n   name     class levels    n missing\n1 Group character      2 1687       0\n                                   distribution\n1 ILEC (98.6%), CLEC (1.4%)                    \n\nquantitative variables:  \n  name   class min   Q1 median   Q3   max     mean       sd    n missing\n1 Time numeric   0 0.75   3.63 7.35 191.6 8.522009 14.78848 1687       0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(Time ~ Group, data = verizon)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     CLEC      ILEC \n16.509130  8.411611 \n```\n:::\n\n```{.r .cell-code}\nobs_diff_verizon <- diffmean(Time ~ Group, data = verizon)\nobs_diff_verizon\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndiffmean \n-8.09752 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist_verizon <- do(1000) * diffmean(Time ~ shuffle(Group), data = verizon)\ngf_histogram(data = null_dist_verizon, ~ diffmean) %>% \n  gf_vline(xintercept = obs_diff_wings, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-7-1.png){width=50% height=50%}\n:::\n\n```{.r .cell-code}\nprop1(~ diffmean >= obs_diff_wings, data = null_dist_verizon)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n prop_TRUE \n0.01798202 \n```\n:::\n:::\n\n\n### Case Story-3: Recidivism\n\nDo criminals released after a jail term commit crimes again?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecidivism <- read.csv(\"../../../../../materials/data/resampling/Recidivism.csv\")\ninspect(recidivism)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n     name     class levels     n missing\n1  Gender character      2 17019       3\n2     Age character      5 17019       3\n3   Age25 character      2 17019       3\n4 Offense character      2 17022       0\n5   Recid character      2 17022       0\n6    Type character      3 17022       0\n                                   distribution\n1 M (87.7%), F (12.3%)                         \n2 25-34 (36.6%), 35-44 (23.7%) ...             \n3 Over 25 (81.9%), Under 25 (18.1%)            \n4 Felony (80.6%), Misdemeanor (19.4%)          \n5 No (68.4%), Yes (31.6%)                      \n6 No Recidivism (68.4%), New (20.2%) ...       \n\nquantitative variables:  \n  name   class min  Q1 median  Q3  max     mean       sd    n missing\n1 Days integer   0 241    418 687 1095 473.3275 283.1393 5386   11636\n```\n:::\n:::\n\n\nThere are some missing values in the variable <tt> `Age25`</tt>. The\n<tt> `complete.cases`</tt> command gives the row numbers where values\nare not missing. We create a new data frame omitting the rows where\nthere is a missing value in the <tt> 'Age25' </tt> variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecidivism_na <- recidivism %>% tidyr::drop_na(Age25)\n```\n:::\n\n\nAlso, the variable <tt>`Recid`</tt> is a factor variable coded \"Yes\" or\n\"No\". We convert it to a numeric variable of 1's and 0's.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecidivism_na <- recidivism_na %>% mutate(Recid2 = ifelse(Recid==\"Yes\", 1, 0))\n\nobs_diff_recid <- diffmean( Recid2 ~ Age25, data = recidivism_na)\nobs_diff_recid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  diffmean \n0.05919913 \n```\n:::\n\n```{.r .cell-code}\nnull_dist_recid <- do(1000) * diffmean( Recid2 ~ shuffle(Age25), data = recidivism_na)\n\ngf_histogram( ~ diffmean, data = null_dist_recid) %>% \n  gf_vline(xintercept = obs_diff_recid, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-10-1.png){width=50% height=50%}\n:::\n:::\n\n\n### Case Study-4: Matched Pairs: Results from a diving championship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiving2017 <- read.csv(\"../../../../../materials/data/resampling/Diving2017.csv\")\nhead(Diving2017)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Name     Country Semifinal  Final\n1 CHEONG Jun Hoong    Malaysia    325.50 397.50\n2         SI Yajie       China    382.80 396.00\n3         REN Qian       China    367.50 391.95\n4       KIM Mi Rae North Korea    346.00 385.55\n5       WU Melissa   Australia    318.70 370.20\n6    KIM Kuk Hyang North Korea    360.85 360.00\n```\n:::\n\n```{.r .cell-code}\ninspect(Diving2017)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n     name     class levels  n missing\n1    Name character     12 12       0\n2 Country character      8 12       0\n                                   distribution\n1  SI Yajie (8.3%) ...                         \n2 Canada (16.7%), China (16.7%) ...            \n\nquantitative variables:  \n       name   class    min       Q1  median      Q3   max    mean       sd  n\n1 Semifinal numeric 313.70 322.2000 325.625 356.575 382.8 338.500 22.94946 12\n2     Final numeric 283.35 318.5875 358.925 387.150 397.5 350.475 40.02204 12\n  missing\n1       0\n2       0\n```\n:::\n:::\n\n\nThe data is made up of **paired** observations per swimmer. So we need\nto take the difference between the two swim records for *each* swimmer\nand then shuffle the differences to either polarity. Another way to look\nat this is to shuffle the records between `Semifinal` and `Final` on a\nper Swimmer basis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiving2017\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     Name     Country Semifinal  Final\n1        CHEONG Jun Hoong    Malaysia    325.50 397.50\n2                SI Yajie       China    382.80 396.00\n3                REN Qian       China    367.50 391.95\n4              KIM Mi Rae North Korea    346.00 385.55\n5              WU Melissa   Australia    318.70 370.20\n6           KIM Kuk Hyang North Korea    360.85 360.00\n7         ITAHASHI Minami       Japan    313.70 357.85\n8        BENFEITO Meaghan      Canada    355.15 331.40\n9          PAMG Pandelela    Malaysia    322.75 322.40\n10        CHAMANDY Olivia      Canada    320.55 307.15\n11       PARRATTO Jessica         USA    322.75 302.35\n12 MURILLO URREA Carolina    Colombia    325.75 283.35\n```\n:::\n\n```{.r .cell-code}\nDiving2017 %>% diffmean(data = ., Final ~ Semifinal, only.2 = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  318.7-313.7  320.55-318.7 322.75-320.55  325.5-322.75  325.75-325.5 \n       12.350       -63.050         5.225        85.125      -114.150 \n   346-325.75    355.15-346 360.85-355.15  367.5-360.85   382.8-367.5 \n      102.200       -54.150        28.600        31.950         4.050 \n```\n:::\n\n```{.r .cell-code}\nobs_diff_swim <- mean(~ Final - Semifinal, data = Diving2017)\nobs_diff_swim\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 11.975\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npolarity <- c(rep(1, 6), rep(-1,6))\npolarity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1\n```\n:::\n\n```{.r .cell-code}\nnull_dist_swim <- do(100000) * mean(data = Diving2017, \n                                    ~(Final - Semifinal) * resample(polarity,\n                                                    replace = TRUE))\nnull_dist_swim %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        mean\n1 -0.8333333\n2  0.2583333\n3  3.2583333\n4 -4.7916667\n5 -9.4333333\n6 17.2750000\n```\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_swim, ~mean) %>% \n  gf_vline(xintercept = obs_diff_swim, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-13-1.png){width=50% height=50%}\n:::\n:::\n\n\n### Case Study #5: Flight Delays\n\nLaGuardia Airport (LGA) is one of three major airports that serves the\nNew York City metropolitan area. In 2008, over 23 million passengers and\nover 375 000 planes flew in or out of LGA. United Airlines and America\nAirlines are two major airlines that schedule services at LGA. The data\nset `FlightDelays` contains information on all 4029 departures of these\ntwo airlines from LGA during May and June 2009.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflightDelays <- read.csv(\"../../../../../materials/data/resampling/FlightDelays.csv\")\n\ninspect(flightDelays)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n         name     class levels    n missing\n1     Carrier character      2 4029       0\n2 Destination character      7 4029       0\n3  DepartTime character      5 4029       0\n4         Day character      7 4029       0\n5       Month character      2 4029       0\n6   Delayed30 character      2 4029       0\n                                   distribution\n1 AA (72.1%), UA (27.9%)                       \n2 ORD (44.3%), DFW (22.8%), MIA (15.1%) ...    \n3 8-Noon (26.1%), Noon-4pm (26%) ...           \n4 Fri (15.8%), Mon (15.6%), Tue (15.6%) ...    \n5 June (50.4%), May (49.6%)                    \n6 No (85.2%), Yes (14.8%)                      \n\nquantitative variables:  \n          name   class min   Q1 median   Q3  max      mean         sd    n\n1           ID integer   1 1008   2015 3022 4029 2015.0000 1163.21645 4029\n2     FlightNo integer  71  371    691  787 2255  827.1035  551.30939 4029\n3 FlightLength integer  68  155    163  228  295  185.3011   41.78783 4029\n4        Delay integer -19   -6     -3    5  693   11.7379   41.63050 4029\n  missing\n1       0\n2       0\n3       0\n4       0\n```\n:::\n:::\n\n\nThe variables in the `flightDelays` dataset are:\n\n| Variable     | Description                                                 |\n|------------------|------------------------------------------------------|\n| Carrier      | UA=United Airlines, AA=American Airlines                    |\n| FlightNo     | Flight number                                               |\n| Destination  | Airport code                                                |\n| DepartTime   | Scheduled departure time in 4 h intervals                   |\n| Day          | Day of the Week                                             |\n| Month        | May or June                                                 |\n| Delay        | Minutes flight delayed (negative indicates early departure) |\n| Delayed30    | Departure delayed more than 30 min? Yes or No               |\n| FlightLength | Length of time of flight (minutes)                          |\n\n: flightDelay dataset variables\n\na)  Let us compute the proportion of times that each carrier's flights\n    was delayed more than 20 min. We will conduct a two-sided test to\n    see if the difference in these proportions is statistically\n    significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop(data = flightDelays, Delay >= 20 ~ Carrier)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nprop_TRUE.AA prop_TRUE.UA \n   0.1713696    0.2226180 \n```\n:::\n\n```{.r .cell-code}\nobs_diff_delay <- diffprop(data = flightDelays, Delay >= 20 ~ Carrier)\nobs_diff_delay\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  diffprop \n0.05124841 \n```\n:::\n:::\n\n\nWe see carrier AA has a 17.13% chance of delays\\>= 20, while UA has\n22.26% chance. The difference is 5.12%. Is this statistically\nsignificant? We take the Delays for both Carriers and perform a\npermutation test by `shuffle` on the `carrier` variable:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist_delay <- do(10000) * diffprop(data = flightDelays, Delay >= 20 ~ shuffle(Carrier))\nnull_dist_delay %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      diffprop\n1  0.014210780\n2  0.006803255\n3  0.017914543\n4  0.003099492\n5 -0.015419322\n6 -0.004308033\n```\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_delay, ~ diffprop) %>% gf_vline(xintercept = obs_diff_delay, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-15-1.png){width=50% height=50%}\n:::\n:::\n\n\nIt appears that the difference indelay times is significant. We can\ncompute the `p-value` based on this test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2* mean(null_dist_delay >= obs_diff_delay)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2e-04\n```\n:::\n:::\n\n\nwhich is very small. Hence we reject the null Hypothesis that there is\nno difference between `carrier`s on `delay times`.\n\nb)  Compute the variance in the flight delay lengths for each carrier.\n    Conduct a test to see if the variance for United Airlines differs\n    from that of American Airlines.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(data = flightDelays, Delay ~ Carrier)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      AA       UA \n1606.457 2037.525 \n```\n:::\n\n```{.r .cell-code}\n# There is no readymade function in mosaic called `diffvar`...so...we construct one\nobs_diff_var <- diff(var(data = flightDelays, Delay ~ Carrier))\nobs_diff_var\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      UA \n431.0677 \n```\n:::\n:::\n\n\nThe difference in variances in `Delay` between the two `carrier`s is\n$-431.0677$. In our Permutation Test, we `shuffle` the `Carrier`\nvariable:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobs_diff_var <- diff(var(data = flightDelays, Delay ~ Carrier))\nnull_dist_var <-\n  do(10000) * diff(var(data = flightDelays, Delay ~ shuffle(Carrier)))\nnull_dist_var %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          UA\n1  679.07128\n2 -139.41403\n3  533.96294\n4 -624.76712\n5  -94.80781\n6  -26.58034\n```\n:::\n\n```{.r .cell-code}\n# The null distribution variable is called `UA`\ngf_histogram(data = null_dist_var, ~ UA) %>% gf_vline(xintercept = obs_diff_delay, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-18-1.png){width=50% height=50%}\n:::\n\n```{.r .cell-code}\n2 * mean(null_dist_var >= obs_diff_var)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2838\n```\n:::\n:::\n\n\nClearly there is no case for a significant difference in variances!\n\n### Case Study #6: Walmart vs Target\n\nIs there a difference in the price of groceries sold by the two\nretailers Target and Walmart? The data set `Groceries` contains a sample\nof grocery items and their prices advertised on their respective web\nsites on one specific day.\n\na)  Inspect the data set, then explain why this is an example of matched\n    pairs data.\nb)  Compute summary statistics of the prices for each store.\nc)  Conduct a permutation test to determine whether or not there is a\n    difference in the mean prices.\nd)  Create a ~~histogram~~ bar-chart of the difference in prices. What\n    is unusual about Quaker Oats Life cereal?\ne)  Redo the hypothesis test without this observation. Do you reach the\n    same conclusion?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroceries <- read.csv(\"../../../../../materials/data/resampling/Groceries.csv\") %>% mutate(Product = stringr::str_squish(Product))\nhead(groceries)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           Product    Size Target Walmart\n1          Kellogg NutriGrain Bars  8 bars   2.50    2.78\n2 Quaker Oats Life Cereal Original    18oz   3.19    6.01\n3       General Mills Lucky Charms  11.50z   3.19    2.98\n4        Quaker Oats Old Fashioned    18oz   2.82    2.68\n5             Nabisco Oreo Cookies 14.3oz    2.99    2.98\n6               Nabisco Chips Ahoy    13oz   2.64    1.98\n```\n:::\n\n```{.r .cell-code}\ninspect(groceries)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n     name     class levels  n missing\n1 Product character     30 30       0\n2    Size character     24 30       0\n                                   distribution\n1 Annie's Macaroni & Cheese (3.3%) ...         \n2 18oz (10%), 12oz (6.7%) ...                  \n\nquantitative variables:  \n     name   class  min     Q1 median    Q3  max     mean       sd  n missing\n1  Target numeric 0.99 1.8275  2.545 3.140 7.99 2.762333 1.582128 30       0\n2 Walmart numeric 1.00 1.7600  2.340 2.955 6.98 2.705667 1.560211 30       0\n```\n:::\n:::\n\n\nWe see that the comparison is to be made between two prices for the\n*same* product, and hence this is one more example of `paired data`, as\nin Case Study #4. Let us plot the prices for the products:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_col(data = groceries,\n       Target ~ Product,\n       fill = \"#0073C299\",\n       width = 0.5 ) %>% \n  gf_col(data = groceries,\n         -Walmart ~ Product,\n         fill = \"#EFC00099\",\n         ylab = \"Prices\",\n         width = 0.5\n       ) %>% \n  gf_col(data = groceries %>% filter(Product == \"Quaker Oats Life Cereal Original\"), \n         -Walmart ~ Product,\n         fill = \"red\", \n         width = 0.5) %>% \n  gf_theme(theme_classic()) %>%\n  gf_theme(ggplot2::theme(axis.text.x = element_text(\n    size = 8,\n    face = \"bold\",\n    vjust = 0,\n    hjust = 1\n  ))) %>% gf_theme(ggplot2::coord_flip())\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-20-1.png){width=50% height=50%}\n:::\n:::\n\n\nWe see that the price difference between Walmart and Target prices is\nhighest for the `Product` named `Quaker Oats Life Cereal Original`. Let\nus check the mean difference in prices:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiffmean(data = groceries, Walmart ~ Target, only.2 = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   1-0.99    1.22-1 1.42-1.22 1.49-1.42 1.59-1.49 1.62-1.59 1.79-1.62 1.94-1.79 \n-0.580000  0.170000  0.210000 -0.100000  0.190000  0.070000  0.180000  0.160000 \n1.99-1.94 2.12-1.99 2.39-2.12  2.5-2.39  2.59-2.5 2.64-2.59 2.79-2.64 2.82-2.79 \n 0.090000  0.010000  0.200000  0.600000 -0.200000 -0.600000  0.660000  0.040000 \n2.99-2.82 3.19-2.99 3.49-3.19 3.99-3.49 4.79-3.99 7.19-4.79 7.99-7.19 \n 0.220000  1.263333 -1.183333 -0.480000  2.290000  2.190000  0.000000 \n```\n:::\n\n```{.r .cell-code}\nobs_diff_price = mean( ~ Walmart - Target, data = groceries)\nobs_diff_price\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.05666667\n```\n:::\n:::\n\n\nLet us perform the pair-wise permutation test on prices, by shuffling\nthe two store names:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolarity <- c(rep(1, 15), rep(-1,15))\npolarity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n[26] -1 -1 -1 -1 -1\n```\n:::\n\n```{.r .cell-code}\nnull_dist_price <- do(100000) * mean(data = groceries, \n                                    ~(Walmart-Target) * resample(polarity,\n                                                    replace = TRUE))\nnull_dist_price %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         mean\n1 0.002666667\n2 0.104666667\n3 0.159333333\n4 0.124666667\n5 0.115333333\n6 0.022000000\n```\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_price, ~mean) %>% \n  gf_vline(xintercept = obs_diff_price, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-22-1.png){width=50% height=50%}\n:::\n\n```{.r .cell-code}\n2*(sum(null_dist_price >= obs_diff_price + 1)/(100000+1)) #P-value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nDoes not seem to be aby significant difference in prices...\n\nSuppose we knock off the Quaker Cereal data item...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhich(groceries$Product == \"Quaker Oats Life Cereal Original\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n\n```{.r .cell-code}\ngroceries_less <- groceries[-2,]\ngroceries_less\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                    Product     Size Target\n1                                   Kellogg NutriGrain Bars   8 bars   2.50\n3                                General Mills Lucky Charms   11.50z   3.19\n4                                 Quaker Oats Old Fashioned     18oz   2.82\n5                                      Nabisco Oreo Cookies  14.3oz    2.99\n6                                        Nabisco Chips Ahoy     13oz   2.64\n7                                Doritos Nacho Cheese Chips     10oz   3.99\n8                                   Cheez-it Original Baked     21oz   4.79\n9                                  Swiss Miss Hot Chocolate 10 count   1.49\n10                        Tazo Chai Classic Latte Black Tea   32 oz    3.49\n11                                Annie's Macaroni & Cheese      6oz   1.79\n12                                      Rice A Roni Chicken    6.9oz   1.00\n13                            Zatarain's Jambalaya Rice Mix      8oz   1.62\n14                                 SPAM Original Lunch Meat     12oz   2.79\n15                           Campbell's Chicken Noodle Soup  10.75oz   0.99\n16                       Dinty Moore Hearty Meals Beef Stew     15oz   1.99\n17                                  Hormel Chili with Beans     15oz   1.94\n18                                    Dole Pineapple Chunks    20 oz   1.59\n19                              Skippy Creamy Peanut Butter   16.3oz   2.59\n20                            Smucker's Strawberry Preserve     18oz   2.99\n21                                     Heinz Tomato Ketchup     32oz   2.99\n22                 Near East Couscous Toasted Pine Nuts mix    5.6oz   2.12\n23                                 Barilla Angel Hair Pasta     16oz   1.42\n24       Betty Crocker Super Moist Chocolate Fudge Cake Mix  15.25oz   1.22\n25                             Kraft Jet-Puffed Marshmllows     16oz   1.99\n26 Dunkin' Donuts Original Blend Medium Roast Ground Coffee     12oz   7.19\n27                             Dove Promises Milk Chocolate   8.87oz   3.19\n28                                                 Skittles     41oz   7.99\n29                         Vlasic Kosher Dill Pickle Spears     24oz   2.39\n30                          Vlasic Old Fashioned Sauerkraut     32oz   1.99\n   Walmart\n1     2.78\n3     2.98\n4     2.68\n5     2.98\n6     1.98\n7     2.50\n8     4.79\n9     1.28\n10    2.98\n11    1.72\n12    1.00\n13    1.54\n14    2.64\n15    1.58\n16    1.98\n17    1.88\n18    1.47\n19    2.58\n20    2.84\n21    2.88\n22    1.98\n23    1.38\n24    1.17\n25    1.96\n26    6.98\n27    3.50\n28    6.98\n29    2.18\n30    1.97\n```\n:::\n\n```{.r .cell-code}\nobs_diff_price_less = mean( ~ Walmart - Target, data = groceries_less)\nobs_diff_price_less\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1558621\n```\n:::\n\n```{.r .cell-code}\npolarity_less <- c(rep(1, 15), rep(-1,14)) # Due to resampling this small bias makes no difference\nnull_dist_price_less <- do(100000) * mean(data = groceries_less, \n                                    ~(Walmart-Target) * resample(polarity_less,\n                                                    replace = TRUE))\nnull_dist_price_less %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         mean\n1  0.15655172\n2  0.01448276\n3  0.03310345\n4  0.05586207\n5  0.02689655\n6 -0.07241379\n```\n:::\n\n```{.r .cell-code}\ngf_histogram(data = null_dist_price_less, ~mean) %>% \n  gf_vline(xintercept = obs_diff_price_less, colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-23-1.png){width=50% height=50%}\n:::\n\n```{.r .cell-code}\n1- mean(null_dist_price_less >= obs_diff_price_less) #P-value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0155\n```\n:::\n:::\n\n\n### Case Study 7: Proportions between Categorical Variables\n\nLet us try a dataset with Qualitative / Categorical data. This is a\nGeneral Social Survey dataset, and we have people with different levels\nof `Education` stating their opinion on the `Death Penalty`. We want to\nknow if these two Categorical variables have a correlation, i.e. can the\nopinions in favour of the Death Penalty be explained by the Education\nlevel?\n\nSince data is Categorical, we need to take `counts` in a table, and then\nimplement a `chi-square test`. In the test, we will permute the\n`Education` variable to see if we can see how significant its *effect\nsize* is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGSS2002 <- read.csv(\"../../../../../materials/data/resampling/GSS2002.csv\")\ninspect(GSS2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ncategorical variables:  \n            name     class levels    n missing\n1         Region character      7 2765       0\n2         Gender character      2 2765       0\n3           Race character      3 2765       0\n4      Education character      5 2760       5\n5        Marital character      5 2765       0\n6       Religion character     13 2746      19\n7          Happy character      3 1369    1396\n8         Income character     24 1875     890\n9       PolParty character      8 2729      36\n10      Politics character      7 1331    1434\n11     Marijuana character      2  851    1914\n12  DeathPenalty character      2 1308    1457\n13        OwnGun character      3  924    1841\n14        GunLaw character      2  916    1849\n15 SpendMilitary character      3 1324    1441\n16     SpendEduc character      3 1343    1422\n17      SpendEnv character      3 1322    1443\n18      SpendSci character      3 1266    1499\n19        Pres00 character      5 1749    1016\n20      Postlife character      2 1211    1554\n                                    distribution\n1  North Central (24.7%) ...                    \n2  Female (55.6%), Male (44.4%)                 \n3  White (79.1%), Black (14.8%) ...             \n4  HS (53.8%), Bachelors (16.1%) ...            \n5  Married (45.9%), Never Married (25.6%) ...   \n6  Protestant (53.2%), Catholic (24.5%) ...     \n7  Pretty happy (57.3%) ...                     \n8  40000-49999 (9.1%) ...                       \n9  Ind (19.3%), Not Str Dem (18.9%) ...         \n10 Moderate (39.2%), Conservative (15.8%) ...   \n11 Not legal (64%), Legal (36%)                 \n12 Favor (68.7%), Oppose (31.3%)                \n13 No (65.5%), Yes (33.5%) ...                  \n14 Favor (80.5%), Oppose (19.5%)                \n15 About right (46.5%) ...                      \n16 Too little (73.9%) ...                       \n17 Too little (60%) ...                         \n18 About right (49.7%) ...                      \n19 Bush (50.6%), Gore (44.7%) ...               \n20 Yes (80.5%), No (19.5%)                      \n\nquantitative variables:  \n  name   class min  Q1 median   Q3  max mean       sd    n missing\n1   ID integer   1 692   1383 2074 2765 1383 798.3311 2765       0\n```\n:::\n:::\n\n\nNote how *all* variables are Categorical !! `Education` has five\n`levels`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGSS2002 %>% count(Education)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Education    n\n1 Bachelors  443\n2  Graduate  230\n3        HS 1485\n4    Jr Col  202\n5   Left HS  400\n6      <NA>    5\n```\n:::\n\n```{.r .cell-code}\nGSS2002 %>% count(DeathPenalty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  DeathPenalty    n\n1        Favor  899\n2       Oppose  409\n3         <NA> 1457\n```\n:::\n:::\n\n\nLet us drop NA entries in Education and Death Penalty. And set up a\ntable for the chi-square test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss2002 <- GSS2002 %>% \n  dplyr::select(Education, DeathPenalty) %>% \n  tidyr::drop_na(., c(Education, DeathPenalty))\ndim(gss2002)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1307    2\n```\n:::\n\n```{.r .cell-code}\ngss_summary <- gss2002 %>%\n  mutate(\n    Education = factor(\n      Education,\n      levels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\"),\n      labels = c(\"Bachelors\", \"Graduate\", \"Jr Col\", \"HS\", \"Left HS\")\n    ),\n    DeathPenalty = as.factor(DeathPenalty)\n  ) %>%\n  group_by(Education, DeathPenalty) %>%\n  summarise(count = n()) %>% # This is good for a chisq test\n  \n  # Add two more columns to faciltate mosaic/Marrimekko Plot\n  # \n  mutate(edu_count = sum(count), \n         edu_prop = count / sum(count)) %>%\n  ungroup() \n\ngss_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 5\n   Education DeathPenalty count edu_count edu_prop\n   <fct>     <fct>        <int>     <int>    <dbl>\n 1 Bachelors Favor          135       206    0.655\n 2 Bachelors Oppose          71       206    0.345\n 3 Graduate  Favor           64       114    0.561\n 4 Graduate  Oppose          50       114    0.439\n 5 Jr Col    Favor           71        87    0.816\n 6 Jr Col    Oppose          16        87    0.184\n 7 HS        Favor          511       711    0.719\n 8 HS        Oppose         200       711    0.281\n 9 Left HS   Favor          117       189    0.619\n10 Left HS   Oppose          72       189    0.381\n```\n:::\n\n```{.r .cell-code}\n# We can plot a heatmap-like `mosaic chart` for this table, using `ggplot`:\n# https://stackoverflow.com/questions/19233365/how-to-create-a-marimekko-mosaic-plot-in-ggplot2\n\nggplot(data = gss_summary, aes( x = Education, y = edu_prop)) +\n  geom_bar(aes(width = edu_count, fill = DeathPenalty), stat = \"identity\", position = \"fill\", colour = \"black\") +\n  geom_text(aes(label = scales::percent(edu_prop)), position = position_stack(vjust = 0.5)) +\n\n\n# if labels are desired\n facet_grid(~ Education, scales = \"free_x\", space = \"free_x\") + \n  theme(scale_fill_brewer(palette = \"RdYlGn\")) + \n  # theme(panel.spacing.x = unit(0, \"npc\")) + # if no spacing preferred between bars\n  theme_void() \n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-26-1.png){width=50% height=50%}\n:::\n:::\n\n\nLet us now perform the base `chisq test`: We need a `table` and then the\n`chisq` test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_table <- tally(DeathPenalty ~ Education, data = gss2002)\ngss_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Education\nDeathPenalty Bachelors Graduate  HS Jr Col Left HS\n      Favor        135       64 511     71     117\n      Oppose        71       50 200     16      72\n```\n:::\n\n```{.r .cell-code}\n# Get the observed chi-square statistic\nobservedChi2 <- mosaic::chisq(tally(DeathPenalty ~ Education, data = gss2002))\nobservedChi2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nX.squared \n 23.45093 \n```\n:::\n\n```{.r .cell-code}\n# Actual chi-square test\nstats::chisq.test(tally(DeathPenalty ~ Education, data = gss2002))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  tally(DeathPenalty ~ Education, data = gss2002)\nX-squared = 23.451, df = 4, p-value = 0.0001029\n```\n:::\n:::\n\n\nWe should now repeat the test with permutations on `Education`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_chisq <- do(10000) * chisq.test(tally(DeathPenalty ~ shuffle(Education), data = gss2002))\n\nhead(null_chisq)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              X.squared df    p.value                     method alternative\nX-squared...1 8.6011416  4 0.07188007 Pearson's Chi-squared test          NA\nX-squared...2 0.2083601  4 0.99493584 Pearson's Chi-squared test          NA\nX-squared...3 7.8475847  4 0.09732364 Pearson's Chi-squared test          NA\nX-squared...4 7.5569821  4 0.10922272 Pearson's Chi-squared test          NA\nX-squared...5 2.1500668  4 0.70818058 Pearson's Chi-squared test          NA\nX-squared...6 7.6964222  4 0.10335338 Pearson's Chi-squared test          NA\n                                                                  data .row\nX-squared...1 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1\nX-squared...2 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1\nX-squared...3 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1\nX-squared...4 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1\nX-squared...5 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1\nX-squared...6 tally(DeathPenalty ~ shuffle(Education), data = gss2002)    1\n              .index\nX-squared...1      1\nX-squared...2      2\nX-squared...3      3\nX-squared...4      4\nX-squared...5      5\nX-squared...6      6\n```\n:::\n\n```{.r .cell-code}\ngf_histogram( ~ X.squared, data = null_chisq) %>% \n  gf_vline(xintercept = observedChi2, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-28-1.png){width=50% height=50%}\n:::\n\n```{.r .cell-code}\ngf_histogram( ~ p.value, data = null_chisq, binwidth = 0.1, center = 0.05)\n```\n\n::: {.cell-output-display}\n![](permutation_files/figure-html/unnamed-chunk-28-2.png){width=50% height=50%}\n:::\n:::\n\n\nSo we would conclude that `Education` has a significant effect on\n`DeathPenalty` opinion!\n",
    "supporting": [
      "permutation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}